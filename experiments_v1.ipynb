{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openpyxl\n",
    "import pandas as pd\n",
    "file = \"/Users/k.abhishek/Documents/customer_clusters/customer_onboard_data.xlsx\"\n",
    "df = pd.read_excel(file)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "unique_legal_cluster_ids = {}\n",
    "with open('export.csv', mode ='r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    csvFile = list(csvFile)\n",
    "    for arr in csvFile:\n",
    "        # print(arr)\n",
    "        \n",
    "        legal_cluster_id = arr[1]\n",
    "        trading_name = arr[4].lower()\n",
    "        country_code = arr[15].lower()\n",
    "        country_name = arr[16].lower()\n",
    "        if unique_legal_cluster_ids.get(legal_cluster_id):\n",
    "            unique_legal_cluster_ids[legal_cluster_id].add((trading_name, country_code, country_name))\n",
    "        else:\n",
    "            unique_legal_cluster_ids[legal_cluster_id] = {(trading_name, country_code, country_name)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(unique_legal_cluster_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "max_display_count =25\n",
    "for legal_cluster_id, trading_names in unique_legal_cluster_ids.items():\n",
    "    if count == max_display_count:\n",
    "        break\n",
    "    count += 1\n",
    "    print(legal_cluster_id, trading_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(unique_legal_cluster_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_countries = {}\n",
    "for legal_cluster_id, company_info in unique_legal_cluster_ids.items():\n",
    "    company_set = set()\n",
    "    for company in company_info:\n",
    "        company_set.add(company[1])\n",
    "    if len(company_set) > 1:\n",
    "        different_countries[legal_cluster_id] = company_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(different_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(different_countries)\n",
    "different_countries_list = {}\n",
    "for legal_cluster_id, trading_names in different_countries.items():\n",
    "    different_countries_list[legal_cluster_id] = list(trading_names) \n",
    "import json\n",
    "print(different_countries_list)\n",
    "with open('legal_cluster_different_countries.json', 'w') as f:\n",
    "    json.dump(different_countries_list, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_legal_cluster_ids_list = {}\n",
    "for legal_cluster_id, trading_names in unique_legal_cluster_ids.items():\n",
    "    unique_legal_cluster_ids_list[legal_cluster_id] = list(trading_names) \n",
    "import json\n",
    "\n",
    "with open('unique_legal_cluster_ids.json', 'w') as f:\n",
    "    json.dump(unique_legal_cluster_ids_list, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legal level matches based on two criteria:\n",
    "1. Name of the customer\n",
    "2. Country \n",
    "\n",
    "#Steps\n",
    "For comparion purposes only:\n",
    "1. lowercase the names and country codes\n",
    "2. Remove special characters from the names\n",
    "3. Remove spaces from the names\n",
    "4. Remove stop words from the names\n",
    "\n",
    "Sort the names and do fuzzy matching with the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stop_words = {'llp', 'ltd', 'llc', 'plc', 'inc', 'corp', 'nv', 'group', 'gmbh', 'sa', 'company', 'corporation', 'limited'}\n",
    "delimiters = {\".\", \",\", \"-\", \"_\", \"'\", \"&\", \"/\", \"\\\\\", \":\", \";\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \" \"}\n",
    "def split_company_name(name):\n",
    "    pattern = '|'.join(map(re.escape, delimiters))\n",
    "    words = re.split(pattern, name)\n",
    "    return [word for word in words if word]\n",
    "\n",
    "def lowercase_company_name(name):\n",
    "    return name.lower()\n",
    "\n",
    "# List of common delimiters\n",
    "def remove_stop_words(words):\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "def clean_company_name(trading_name):\n",
    "    # Lowercase the company name\n",
    "    trading_name = lowercase_company_name(trading_name)\n",
    "    # Split the company name into words\n",
    "    words = split_company_name(trading_name)\n",
    "    # Remove stop words\n",
    "    clean_name = remove_stop_words(words)\n",
    "    return clean_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('export.csv', mode ='r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    data = list(csvFile)\n",
    "# data = data[:1000]\n",
    "corpus_ratio = 0.9\n",
    "num_customer_corpus = int(len(data) * corpus_ratio)\n",
    "testing_cusomter_corpus = []\n",
    "existing_legal_cluster_ids = set()\n",
    "existing_trading_name = {}\n",
    "\n",
    "corpus_country_hierarchy = {}\n",
    "\n",
    "for idx, arr in enumerate(data[1:]):\n",
    "    # print(arr)\n",
    "    legal_cluster_id = arr[1]\n",
    "    trading_name = arr[4].lower()\n",
    "    country_code = arr[15].lower()\n",
    "    country_name = arr[16].lower()\n",
    "    if idx < num_customer_corpus:\n",
    "        existing_legal_cluster_ids.add(legal_cluster_id)\n",
    "        # cleaning the trading name for comparison\n",
    "        clean_trading_name = clean_company_name(trading_name)\n",
    "        existing_trading_name[clean_trading_name] = (legal_cluster_id, trading_name, country_code, country_name)\n",
    "        if corpus_country_hierarchy.get(country_code):\n",
    "            corpus_country_hierarchy[country_code][clean_trading_name] = (legal_cluster_id, trading_name, country_code, country_name)\n",
    "        else:\n",
    "            corpus_country_hierarchy[country_code] = {clean_trading_name: (legal_cluster_id, trading_name, country_code, country_name)}\n",
    "    \n",
    "    else:\n",
    "        company_info = (legal_cluster_id, trading_name, country_code, country_name)\n",
    "        testing_cusomter_corpus.append(company_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(existing_trading_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testing_cusomter_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz, process\n",
    "import heapq\n",
    "def sorted_tokens(name):\n",
    "    return \" \".join(sorted(name.split()))\n",
    "\n",
    "#calculates the minimum number of edits (insertions, deletions, substitutions) needed to transform one string into another.\n",
    "def levenshtein_matching_score(input_name, name):\n",
    "    levenshtein_matching_score = fuzz.ratio(input_name, name)\n",
    "    return levenshtein_matching_score\n",
    "\n",
    "#split strings into tokens (words) and compare the intersection and order of these tokens. This is useful for handling different word orders or missing words in one string.\n",
    "def token_set_matching_score(input_name, name):\n",
    "    token_set_matching_score = fuzz.token_set_ratio(input_name, name)\n",
    "    return token_set_matching_score\n",
    "\n",
    "#focus on finding matching subsequences within strings. This is beneficial when comparing strings with extra content or typos.\n",
    "def partial_matching_score(input_name, name):\n",
    "    partial_matching_score = fuzz.partial_ratio(input_name, name)\n",
    "    return partial_matching_score\n",
    "\n",
    "#focus on finding matching subsequences within strings. This is beneficial when comparing strings with extra content or typos.\n",
    "def substring_matching_score(input_name, name):\n",
    "    substring_matching_score = fuzz.partial_ratio(input_name, name)\n",
    "    return substring_matching_score\n",
    "\n",
    "#split strings into tokens (words) and compare the intersection and order of these tokens. This is useful for handling different word orders or missing words in one string.\n",
    "def token_sort_ratio_score(input_name, name):\n",
    "    score = fuzz.token_sort_ratio(input_name, name)\n",
    "    return score\n",
    "# Matching\n",
    "max_number_matches = 5\n",
    "def match_name(input_name, corpus):\n",
    "    input_name = clean_company_name(input_name)\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    top_matches = []\n",
    "    heapq.heapify(top_matches)\n",
    "    similarity_measures = { \n",
    "        \"levenshtein_matching_score\" : (1, levenshtein_matching_score),\n",
    "        \"token_set_matching_score\" : (1, token_set_matching_score),\n",
    "        \"substring_matching_score\" : (1, substring_matching_score),\n",
    "        \"partial_matching_score\" : (1, partial_matching_score),\n",
    "        \"token_sort_ratio_score\" : (1, token_sort_ratio_score)\n",
    "    }\n",
    "    for name in corpus:\n",
    "        num_measures = 0\n",
    "        total_score = 0\n",
    "        for function_check in similarity_measures.values():\n",
    "            check, func = function_check\n",
    "            if check:\n",
    "                score = func(input_name, name)\n",
    "                total_score += score\n",
    "                num_measures +=1\n",
    "            if num_measures == 0:\n",
    "                combined_score = 0\n",
    "            else:\n",
    "                combined_score = total_score / num_measures\n",
    "        if len(top_matches) < max_number_matches:\n",
    "            heapq.heappush(top_matches, (combined_score, name))\n",
    "        else:\n",
    "            heapq.heappushpop(top_matches, (combined_score, name))\n",
    "        if combined_score > best_score:\n",
    "            best_score = combined_score\n",
    "            best_match = name\n",
    "    \n",
    "    return best_match, best_score, top_matches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "corpus = list(existing_trading_name.keys())\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "not_applicable = 0\n",
    "result = {}\n",
    "result_tuple = {}\n",
    "\n",
    "def reformat_top_matches(top_matches):\n",
    "    matches = {}\n",
    "    sorted_matches = sorted(top_matches, key=lambda x: x[0], reverse=True)\n",
    "    rank = 1\n",
    "    for idx, match in enumerate(sorted_matches):\n",
    "        score = match[0]\n",
    "        clean_trading_name = match[1]\n",
    "        trading_name = existing_trading_name[clean_trading_name][1]\n",
    "        legal_cluster_id = existing_trading_name[clean_trading_name][0]\n",
    "        match_info = {\n",
    "            \"score\" : score,\n",
    "            \"clean_trading_name\" : clean_trading_name,\n",
    "            \"trading_name\" : trading_name,\n",
    "            \"legal_cluster_id\" : legal_cluster_id\n",
    "        }\n",
    "        flag = False\n",
    "        for r, existing_match in matches.items():\n",
    "            if existing_match[0][\"legal_cluster_id\"] == legal_cluster_id:\n",
    "                matches[r].append(match_info)\n",
    "                flag = True\n",
    "                break\n",
    "        if not flag:\n",
    "            matches[rank] = [match_info]\n",
    "            rank += 1\n",
    "\n",
    "    return matches\n",
    "    \n",
    "for test_customer in tqdm(testing_cusomter_corpus):\n",
    "    legal_cluster_id, trading_name, country_code, country_name = test_customer\n",
    "    clean_trading_name = clean_company_name(trading_name)\n",
    "    # reducing the search range by country code\n",
    "    if legal_cluster_id in existing_legal_cluster_ids and corpus_country_hierarchy.get(country_code):\n",
    "        country_wise_corpus = corpus_country_hierarchy[country_code]\n",
    "        corpus = list(country_wise_corpus.keys())\n",
    "        best_match, best_score, top_matches = match_name(clean_trading_name, corpus)\n",
    "        matched_company_info = existing_trading_name.get(best_match)\n",
    "        # print(trading_name)\n",
    "        # print( best_match, best_score)\n",
    "\n",
    "\n",
    "        # result[trading_name] = reformat_top_matches(top_matches)\n",
    "        reformatted_top_matches = reformat_top_matches(top_matches)\n",
    "        # if legal_cluster_id == matched_company_info[0]:\n",
    "        #     correct +=1\n",
    "        # else:\n",
    "        #     incorrect +=1\n",
    "        if reformatted_top_matches.get(1):\n",
    "            if legal_cluster_id == reformatted_top_matches[1][0][\"legal_cluster_id\"]:\n",
    "                correct +=1\n",
    "            else:\n",
    "                incorrect +=1\n",
    "        str(test_customer)\n",
    "        result[str(test_customer)] = reformat_top_matches(top_matches)\n",
    "        \n",
    "    else:\n",
    "        not_applicable +=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"levenshtein_matching_score\" : (1, levenshtein_matching_score)\n",
    "\"token_set_matching_score\" : (1, token_set_matching_score)\n",
    "\n",
    "correct, incorrect, not applicable = (724, 462, 9299)\n",
    "\n",
    "\n",
    "(1, 1, 1, 1, 1)\n",
    "(6407, 3575, 94875)\n",
    "0.6418553396113004\n",
    "\n",
    "\n",
    "(0, 0, 0,)\n",
    "\n",
    "Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct, incorrect, not_applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct/(correct + incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_value = \"('7b4f8ac1-0260-3331-baab-6711f756e602', 's s corporation', 'bd', 'bangladesh')\"\n",
    "tuple_value = eval(string_value)\n",
    "print(tuple_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "scores = []\n",
    "verdict = []\n",
    "for key, top_matches in result.items():\n",
    "    test_customer = eval(key)\n",
    "    top_match = top_matches.get(1)[0]\n",
    "    scores.append(top_match[\"score\"])\n",
    "    verdict.append(test_customer[0] == top_match[\"legal_cluster_id\"])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores[:10], verdict[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_true_positive = 0\n",
    "for ver in verdict:\n",
    "    if ver:\n",
    "        count_true_positive +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_true_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('matching_by_name_results_country_filter-1-2-3-4-5_clustered.json', 'w') as f:\n",
    "    json.dump(result, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best match\n",
    "input_name = \"venture nig vince\"\n",
    "best_match, best_score, top_matches = match_name(input_name, corpus)\n",
    "print(f\"Best match: {best_match} with score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz, process\n",
    "def sorted_tokens(name):\n",
    "    return \" \".join(sorted(name.split()))\n",
    "\n",
    "# Matching\n",
    "def match_name(input_name, corpus):\n",
    "    input_name = clean_company_name(input_name)\n",
    "    input_sorted = sorted_tokens(input_name)\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    for name in corpus:\n",
    "        # Compute different similarity measures\n",
    "        raw_score = fuzz.ratio(input_name, name)\n",
    "        \n",
    "        sorted_score = fuzz.ratio(input_sorted, sorted_tokens(name))\n",
    "\n",
    "        # Combine scores\n",
    "        combined_score = (raw_score + sorted_score) / 2\n",
    "        \n",
    "        if combined_score > best_score:\n",
    "            best_score = combined_score\n",
    "            best_match = name\n",
    "    \n",
    "    return best_match, best_score\n",
    "\n",
    "# Find the best match\n",
    "input_name = \"venture nig vince\"\n",
    "best_match, best_score = match_name(input_name, corpus)\n",
    "print(f\"Best match: {best_match} with score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz, process\n",
    "import heapq\n",
    "def sorted_tokens(name):\n",
    "    return \" \".join(sorted(name.split()))\n",
    "\n",
    "def levenshtein_matching_score(input_name, name):\n",
    "    levenshtein_matching_score = fuzz.ratio(input_name, name)\n",
    "    return levenshtein_matching_score\n",
    "\n",
    "def token_set_matching_score(input_name, name):\n",
    "    token_set_matching_score = fuzz.token_set_ratio(input_name, name)\n",
    "    return token_set_matching_score\n",
    "\n",
    "def partial_matching_score(input_name, name):\n",
    "    partial_matching_score = fuzz.partial_ratio(input_name, name)\n",
    "    return partial_matching_score\n",
    "\n",
    "def substring_matching_score(input_name, name):\n",
    "    substring_matching_score = fuzz.partial_ratio(input_name, name)\n",
    "    return substring_matching_score\n",
    "\n",
    "def token_sort_ratio_score(input_name, name):\n",
    "    score = fuzz.token_sort_ratio(input_name, name)\n",
    "    return score\n",
    "# Matching\n",
    "max_number_matches = 5\n",
    "def match_name(input_name, corpus):\n",
    "    input_name = clean_company_name(input_name)\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    top_matches = []\n",
    "    heapq.heapify(top_matches)\n",
    "    similarity_measures = { \n",
    "        \"levenshtein_matching_score\" : (1, levenshtein_matching_score),\n",
    "        \"token_set_matching_score\" : (0, token_set_matching_score),\n",
    "        \"substring_matching_score\" : (0, substring_matching_score),\n",
    "        \"partial_matching_score\" : (0, partial_matching_score),\n",
    "        \"token_sort_ratio_score\" : (1, token_sort_ratio_score)\n",
    "    }\n",
    "    for name in corpus:\n",
    "        num_measures = 0\n",
    "        total_score = 0\n",
    "        for function_check in similarity_measures.values():\n",
    "            check, func = function_check\n",
    "            if check:\n",
    "                score = func(input_name, name)\n",
    "                total_score += score\n",
    "                num_measures +=1\n",
    "            if num_measures == 0:\n",
    "                combined_score = 0\n",
    "            else:\n",
    "                combined_score = total_score / num_measures\n",
    "        if len(top_matches) < max_number_matches:\n",
    "            heapq.heappush(top_matches, (combined_score, name))\n",
    "        else:\n",
    "            heapq.heappushpop(top_matches, (combined_score, name))\n",
    "        if combined_score > best_score:\n",
    "            best_score = combined_score\n",
    "            best_match = name\n",
    "    \n",
    "    return best_match, best_score, top_matches\n",
    "\n",
    "# Find the best match\n",
    "input_name = \"venture nig vince\"\n",
    "best_match, best_score, top_matches = match_name(input_name, corpus)\n",
    "print(f\"Best match: {best_match} with score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
