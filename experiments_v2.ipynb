{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file = \"/Users/k.abhishek/Documents/customer_clusters/customer_onboard_data.xlsx\"\n",
    "df = pd.read_excel(file)\n",
    "print(df.columns)\n",
    "colNum_to_colName = {i:col for i,col in enumerate(df.columns)}\n",
    "print(colNum_to_colName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index(['SITE_CLUSTER_ID', 'LEGAL_CLUSTER_ID', 'customer_cmd_code',\n",
    "       'customer_role_type', 'trading_name', 'street_no', 'address_line1',\n",
    "       'pobox', 'address_line2', 'address_line3', 'district', 'city',\n",
    "       'postal_code', 'state_code', 'state_name', 'country_code',\n",
    "       'country_name', 'phone_type', 'isd_country_code', 'isd_dialing_code',\n",
    "       'extension_number', 'phone_num', 'create_time', 'customer_cmd_code.1',\n",
    "       'BVD', 'BVD_HQ', 'BVD_GUO', 'TAXNO1', 'TAXNO2', 'TAXNO3', 'TAXNO4',\n",
    "       'TAXNO5', 'VATREG'],\n",
    "      dtype='object')\n",
    "{0: 'SITE_CLUSTER_ID', 1: 'LEGAL_CLUSTER_ID', 2: 'customer_cmd_code', 3: 'customer_role_type', 4: 'trading_name', 5: 'street_no', 6: 'address_line1', 7: 'pobox', 8: 'address_line2', 9: 'address_line3', 10: 'district', 11: 'city', 12: 'postal_code', 13: 'state_code', 14: 'state_name', 15: 'country_code', 16: 'country_name', 17: 'phone_type', 18: 'isd_country_code', 19: 'isd_dialing_code', 20: 'extension_number', 21: 'phone_num', 22: 'create_time', 23: 'customer_cmd_code.1', 24: 'BVD', 25: 'BVD_HQ', 26: 'BVD_GUO', 27: 'TAXNO1', 28: 'TAXNO2', 29: 'TAXNO3', 30: 'TAXNO4', 31: 'TAXNO5', 32: 'VATREG'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from csv\n",
    "import csv\n",
    "\n",
    "customer_cmd_code_to_tax_num = {}\n",
    "with open('export.csv', mode ='r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    data = list(csvFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if customer_cmd_code is unique\n",
    "customer_cmd_code_to_legal_cluster_id = {}\n",
    "for row in data:\n",
    "    customer_cmd_code = row[2]\n",
    "    legal_cluster_id = row[1]\n",
    "    if customer_cmd_code in customer_cmd_code_to_legal_cluster_id:\n",
    "        customer_cmd_code_to_legal_cluster_id[customer_cmd_code].add(legal_cluster_id)\n",
    "    else:  \n",
    "        customer_cmd_code_to_legal_cluster_id[customer_cmd_code] = set([legal_cluster_id])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_more_legal_cluster_id = 0\n",
    "for key in customer_cmd_code_to_legal_cluster_id:\n",
    "    if len(customer_cmd_code_to_legal_cluster_id[key]) > 1:\n",
    "        count_more_legal_cluster_id += 1\n",
    "print(count_more_legal_cluster_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, arr in enumerate(data[1:]):\n",
    "    tax = set()\n",
    "    for i in range(27, 33):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            # print(type(arr[i]))\n",
    "            tax.add(arr[i])\n",
    "            # print(tax)\n",
    "\n",
    "    if customer_cmd_code_to_tax_num.get(arr[2]) is None:\n",
    "        customer_cmd_code_to_tax_num[arr[2]] = tax\n",
    "    else:\n",
    "        customer_cmd_code_to_tax_num[arr[2]] = customer_cmd_code_to_tax_num[arr[2]].union(tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_tax_num = 0\n",
    "tax_num_exists = 0\n",
    "more_than_one_tax_num = 0\n",
    "for key, value in customer_cmd_code_to_tax_num.items():\n",
    "    if len(value) == 0:\n",
    "        no_tax_num += 1\n",
    "    else:\n",
    "        tax_num_exists += 1\n",
    "    if len(value) > 1:\n",
    "        more_than_one_tax_num += 1\n",
    "    # count -= 1\n",
    "    # if count == 0:\n",
    "    #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_than_one_tax_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_num_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, arr in enumerate(data[1:]):\n",
    "    print(type(arr))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "customer_cmd_code_to_bvd = {}\n",
    "# with open('export.csv', mode ='r') as file:\n",
    "#     csvFile = csv.reader(file)\n",
    "#     data = list(csvFile)\n",
    "\n",
    "for idx, arr in enumerate(data[1:]):\n",
    "    tax = set()\n",
    "    for i in range(24, 27):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            # print(type(arr[i]))\n",
    "            tax.add(arr[i])\n",
    "            # print(tax)\n",
    "\n",
    "    if customer_cmd_code_to_bvd.get(arr[2]) is None:\n",
    "        customer_cmd_code_to_bvd[arr[2]] = tax\n",
    "    else:\n",
    "        customer_cmd_code_to_bvd[arr[2]] = customer_cmd_code_to_bvd[arr[2]].union(tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_bvd_num = 0\n",
    "bvd_num_exists = 0\n",
    "more_than_one_bvd_num = 0\n",
    "# count = 10\n",
    "for key, value in customer_cmd_code_to_bvd.items():\n",
    "    if len(value) == 0:\n",
    "        no_bvd_num += 1\n",
    "    else:\n",
    "        bvd_num_exists += 1\n",
    "    if len(value) > 1:\n",
    "        more_than_one_bvd_num += 1\n",
    "    # count -= 1\n",
    "    # if count == 0:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(more_than_one_bvd_num)\n",
    "print(no_bvd_num)\n",
    "print(bvd_num_exists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for now generating 3 types of corpus for comparison:\n",
    "1. set of tax number\n",
    "2. set of bvd number\n",
    "3. dict of customer_cmd_code to list of entries corresponding to the same customer_cmd_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stop_words = {'llp', 'ltd', 'llc', 'plc', 'inc', 'corp', 'nv', 'group', 'gmbh', 'sa', 'company', 'corporation', 'limited'}\n",
    "delimiters = {\".\", \",\", \"-\", \"_\", \"'\", \"&\", \"/\", \"\\\\\", \":\", \";\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \" \"}\n",
    "def split_company_name(name):\n",
    "    pattern = '|'.join(map(re.escape, delimiters))\n",
    "    words = re.split(pattern, name)\n",
    "    return [word for word in words if word]\n",
    "\n",
    "def lowercase_company_name(name):\n",
    "    return name.lower()\n",
    "\n",
    "# List of common delimiters\n",
    "def remove_stop_words(words):\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "def clean_company_name(trading_name):\n",
    "    # Lowercase the company name\n",
    "    trading_name = lowercase_company_name(trading_name)\n",
    "    # Split the company name into words\n",
    "    words = split_company_name(trading_name)\n",
    "    # Remove stop words\n",
    "    clean_name = remove_stop_words(words)\n",
    "    return clean_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_number_matches = 5\n",
    "from rapidfuzz import fuzz, process\n",
    "import heapq\n",
    "def sorted_tokens(name):\n",
    "    return \" \".join(sorted(name.split()))\n",
    "\n",
    "#calculates the minimum number of edits (insertions, deletions, substitutions) needed to transform one string into another.\n",
    "#For typos or minor spelling variations\n",
    "def levenshtein_matching_score(input_name, name):\n",
    "    levenshtein_matching_score = fuzz.ratio(input_name, name)\n",
    "    return levenshtein_matching_score\n",
    "\n",
    "#split strings into tokens (words) and compare the intersection and order of these tokens. This is useful for handling different word orders or missing words in one string.\n",
    "def token_set_matching_score(input_name, name):\n",
    "    token_set_matching_score = fuzz.token_set_ratio(input_name, name)\n",
    "    return token_set_matching_score\n",
    "\n",
    "#For situations with extra content or partial matches:\n",
    "def partial_matching_score(input_name, name):\n",
    "    partial_matching_score = fuzz.partial_token_set_ratio(input_name, name)\n",
    "    return partial_matching_score\n",
    "\n",
    "#focus on finding matching subsequences within strings. This is beneficial when comparing strings with extra content or typos.\n",
    "#For typos or minor spelling variations\n",
    "def substring_matching_score(input_name, name):\n",
    "    substring_matching_score = fuzz.partial_ratio(input_name, name)\n",
    "    return substring_matching_score\n",
    "\n",
    "#split strings into tokens (words) and compare the intersection and order of these tokens. This is useful for handling different word orders or missing words in one string.\n",
    "def token_sort_ratio_score(input_name, name):\n",
    "    score = fuzz.token_sort_ratio(input_name, name)\n",
    "    return score\n",
    "# Matching\n",
    "\n",
    "def match_name(input_name, corpus):\n",
    "    input_name = clean_company_name(input_name)\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    top_matches = []\n",
    "    heapq.heapify(top_matches)\n",
    "    similarity_measures = { \n",
    "        \"levenshtein_matching_score\" : (0, levenshtein_matching_score),\n",
    "        \"token_set_matching_score\" : (1, token_set_matching_score),\n",
    "        \"substring_matching_score\" : (1, substring_matching_score),\n",
    "        \"partial_matching_score\" : (1, partial_matching_score),\n",
    "        \"token_sort_ratio_score\" : (0, token_sort_ratio_score)\n",
    "    }\n",
    "    for customer_info in corpus:\n",
    "        name = customer_info[4]\n",
    "        name = clean_company_name(name)\n",
    "        num_measures = 0\n",
    "        total_score = 0\n",
    "        for function_check in similarity_measures.values():\n",
    "            check, func = function_check\n",
    "            if check:\n",
    "                score = func(input_name, name)\n",
    "                total_score += score\n",
    "                num_measures +=1\n",
    "            if num_measures == 0:\n",
    "                combined_score = 0\n",
    "            else:\n",
    "                combined_score = total_score / num_measures\n",
    "        if len(top_matches) < max_number_matches:\n",
    "            heapq.heappush(top_matches, (combined_score, customer_info))\n",
    "        else:\n",
    "            heapq.heappushpop(top_matches, (combined_score, customer_info))\n",
    "        if combined_score > best_score:\n",
    "            best_score = combined_score\n",
    "            best_match = customer_info\n",
    "    \n",
    "    return best_match, best_score, top_matches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing data for testing\n",
    "corpus_ratio = 0.9\n",
    "\n",
    "num_customer_corpus = int(len(data) * corpus_ratio)\n",
    "\n",
    "testing_customer_corpus = []\n",
    "\n",
    "unique_tax_numbers = {}\n",
    "unique_bvd_numbers = {}\n",
    "corpus_customer_cmd_code = {}\n",
    "corpus_legal_cluster_id = {}\n",
    "country_wise_corpus = {}\n",
    "for idx, arr in enumerate(data[1:num_customer_corpus]):\n",
    "    country_name = arr[16].lower()\n",
    "    for i in range(24, 27):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            if unique_bvd_numbers.get(arr[i].lower()):\n",
    "                unique_bvd_numbers[arr[i].lower()].append(arr)\n",
    "            else:\n",
    "                unique_bvd_numbers[arr[i].lower()] = [arr]\n",
    "            # unique_bvd_numbers[arr[i]] = arr\n",
    "    for i in range(27, 33):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            if unique_tax_numbers.get(arr[i].lower()):\n",
    "                unique_tax_numbers[arr[i].lower()].append(arr)\n",
    "            else:\n",
    "                unique_tax_numbers[arr[i].lower()] = [arr]\n",
    "            # unique_tax_numbers[arr[i]] = arr\n",
    "\n",
    "    if country_wise_corpus.get(country_name):\n",
    "        country_wise_corpus[country_name].append(arr)\n",
    "    else:\n",
    "        country_wise_corpus[country_name] = [arr]\n",
    "    \n",
    "    customer_cmd_code = arr[2].lower()\n",
    "    if corpus_customer_cmd_code.get(customer_cmd_code):\n",
    "        corpus_customer_cmd_code[customer_cmd_code].append(arr)\n",
    "    else:    \n",
    "        corpus_customer_cmd_code[customer_cmd_code] = [arr]\n",
    "    \n",
    "    legal_cluster_id = arr[1].lower()\n",
    "    if corpus_legal_cluster_id.get(legal_cluster_id):\n",
    "        corpus_legal_cluster_id[legal_cluster_id].append(arr)\n",
    "    else:\n",
    "        corpus_legal_cluster_id[legal_cluster_id] = [arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tax_numbers(arr):\n",
    "    unique_tax_numbers = set()\n",
    "    for i in range(27, 33):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            unique_tax_numbers.add(arr[i].lower())\n",
    "    return unique_tax_numbers\n",
    "\n",
    "def extract_bvd_numbers(arr):\n",
    "    unique_bvd_numbers = set()\n",
    "    for i in range(24, 27):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            unique_bvd_numbers.add(arr[i].lower())\n",
    "    return unique_bvd_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def match_tax(arr):\n",
    "    tax = extract_tax_numbers(arr)\n",
    "    for tax_num in tax:\n",
    "        if tax_num in unique_tax_numbers:\n",
    "            return unique_tax_numbers[tax_num]\n",
    "    return None\n",
    "\n",
    "def match_bvd(arr):\n",
    "    bvd = extract_bvd_numbers(arr)\n",
    "    for bvd_num in bvd:\n",
    "        if bvd_num in unique_bvd_numbers:\n",
    "            return unique_bvd_numbers[bvd_num]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_top_matches(top_matches):\n",
    "    matches = {}\n",
    "    sorted_matches = sorted(top_matches, key=lambda x: x[0], reverse=True)\n",
    "    rank = 1\n",
    "    for idx, match in enumerate(sorted_matches):\n",
    "        score = match[0]\n",
    "        match_info = {\n",
    "            \"score\" : score,\n",
    "            \"customer_info\" : match[1]\n",
    "        }\n",
    "        flag = False\n",
    "        legal_cluster_id = match[1][1]\n",
    "        # print(match)\n",
    "        # print(legal_cluster_id)\n",
    "        for r, existing_match in matches.items():\n",
    "            if existing_match[0][\"customer_info\"][1] == legal_cluster_id:\n",
    "                matches[r].append(match_info)\n",
    "                flag = True\n",
    "                break\n",
    "        if not flag:\n",
    "            matches[rank] = [match_info]\n",
    "            rank += 1\n",
    "    # print(matches)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "success = 0\n",
    "failure = 0\n",
    "not_applicable = 0\n",
    "result = {}\n",
    "for arr in tqdm(data[num_customer_corpus:]):\n",
    "    customer_cmd_code = arr[2].lower()\n",
    "    # print(customer_cmd_code)\n",
    "    legal_cluster_id = arr[1].lower()\n",
    "    #checking if the test customer is in the corpus for the comparison\n",
    "    if legal_cluster_id in corpus_legal_cluster_id.keys():\n",
    "        matches = {}\n",
    "        #tax matching\n",
    "        tax_match = match_tax(arr)\n",
    "        if tax_match:\n",
    "            success += 1\n",
    "            matches[1] = tax_match\n",
    "            result[str(arr)] = matches\n",
    "            continue\n",
    "        #bvd matching\n",
    "        bvd_match = match_bvd(arr)\n",
    "        if bvd_match:\n",
    "            success += 1\n",
    "            matches[1] = bvd_match\n",
    "            result[str(arr)] = matches\n",
    "            continue\n",
    "\n",
    "        #trading name matching after country filtering \n",
    "        country_name = arr[16].lower()\n",
    "        #filtering by country and hence reducing our search space\n",
    "        filtered_corpus = country_wise_corpus[country_name]\n",
    "        company_name = arr[4]\n",
    "        cleaned_company_name = clean_company_name(company_name)\n",
    "        best_match, best_score, top_matches = match_name(cleaned_company_name, filtered_corpus)\n",
    "        reformatted_top_matches = reformat_top_matches(top_matches)\n",
    "        # if legal_cluster_id == matched_company_info[0]:\n",
    "        #     correct +=1\n",
    "        # else:\n",
    "        #     incorrect +=1\n",
    "        if reformatted_top_matches.get(1):\n",
    "            # print(reformatted_top_matches[1][0]['customer_info'][1])\n",
    "            if legal_cluster_id == reformatted_top_matches[1][0]['customer_info'][1]:\n",
    "                success +=1\n",
    "            else:\n",
    "                failure +=1\n",
    "        \n",
    "        matches = reformat_top_matches(top_matches)\n",
    "        result[str(arr)] = matches\n",
    "        \n",
    "    else:\n",
    "        not_applicable +=1    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('result_match_tax_bvd_name_country-2-3-4.json', 'w') as f:\n",
    "    json.dump(result, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(success, failure, not_applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success/(failure + success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success + failure + not_applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
