{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file = \"/Users/k.abhishek/Documents/customer_clusters/customer_onboard_data.xlsx\"\n",
    "df = pd.read_excel(file)\n",
    "print(df.columns)\n",
    "colNum_to_colName = {i:col for i,col in enumerate(df.columns)}\n",
    "print(colNum_to_colName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index(['SITE_CLUSTER_ID', 'LEGAL_CLUSTER_ID', 'customer_cmd_code',\n",
    "       'customer_role_type', 'trading_name', 'street_no', 'address_line1',\n",
    "       'pobox', 'address_line2', 'address_line3', 'district', 'city',\n",
    "       'postal_code', 'state_code', 'state_name', 'country_code',\n",
    "       'country_name', 'phone_type', 'isd_country_code', 'isd_dialing_code',\n",
    "       'extension_number', 'phone_num', 'create_time', 'customer_cmd_code.1',\n",
    "       'BVD', 'BVD_HQ', 'BVD_GUO', 'TAXNO1', 'TAXNO2', 'TAXNO3', 'TAXNO4',\n",
    "       'TAXNO5', 'VATREG'],\n",
    "      dtype='object')\n",
    "{0: 'SITE_CLUSTER_ID', 1: 'LEGAL_CLUSTER_ID', 2: 'customer_cmd_code', 3: 'customer_role_type', 4: 'trading_name', 5: 'street_no', 6: 'address_line1', 7: 'pobox', 8: 'address_line2', 9: 'address_line3', 10: 'district', 11: 'city', 12: 'postal_code', 13: 'state_code', 14: 'state_name', 15: 'country_code', 16: 'country_name', 17: 'phone_type', 18: 'isd_country_code', 19: 'isd_dialing_code', 20: 'extension_number', 21: 'phone_num', 22: 'create_time', 23: 'customer_cmd_code.1', 24: 'BVD', 25: 'BVD_HQ', 26: 'BVD_GUO', 27: 'TAXNO1', 28: 'TAXNO2', 29: 'TAXNO3', 30: 'TAXNO4', 31: 'TAXNO5', 32: 'VATREG'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from csv\n",
    "import csv\n",
    "\n",
    "with open('export_all_v2.csv', mode ='r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    data = list(csvFile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_set = set()\n",
    "for idx, arr in enumerate(data[1:]):\n",
    "    country_name = arr[16].lower()\n",
    "    country_set.add(country_name)\n",
    "len(country_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "delimiters = {\".\", \",\", \"-\", \"_\", \"'\", \"&\", \"/\", \"\\\\\", \":\", \";\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \" \"}\n",
    "def split_company_name(name):\n",
    "    pattern = '|'.join(map(re.escape, delimiters))\n",
    "    words = re.split(pattern, name)\n",
    "    return [word for word in words if word]\n",
    "\n",
    "def lowercase_company_name(name):\n",
    "    return name.lower()\n",
    "\n",
    "def clean_country_name(trading_name):\n",
    "    # Lowercase the company name\n",
    "    trading_name = lowercase_company_name(trading_name)\n",
    "    # Split the company name into words\n",
    "    words = split_company_name(trading_name)\n",
    "    # Remove stop words\n",
    "    clean_name = \" \".join(words)\n",
    "    return clean_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in pycountry.countries:\n",
    "    print(country.alpha_2, country.alpha_3, country.name, country.numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['turkey', 'Switzerland', 'wallis and futuna', 'Malawi', 'virgin islands, u.s.', 'Bahrain', 'Moldova, Republic of', 'Ukraine', 'Bahamas', 'Israel', 'Uganda', 'Zambia', 'Solomon Islands', 'Argentina', 'Saint Vincent and the Grenadines', 'China', 'Cyprus', 'Madagascar', 'Gibraltar', 'Uzbekistan', 'Sudan', 'Finland', 'Oman', 'Isle of Man', 'china', 'Romania', 'Turkmenistan', 'Chile', 'Czechia', 'Algeria', 'Cook Islands', 'Dominican Republic', 'United States', 'Australia', 'Indonesia', 'El Salvador', 'Kenya', 'Iran, Islamic Republic of', 'Dominica', 'Bhutan', 'bolivia, plurinational state of', 'Gabon', 'korea, republic of', 'Georgia', 'Guernsey', 'Sri Lanka', 'Kyrgyzstan', 'Djibouti', 'Ethiopia', 'South Sudan', 'russian federation', 'Kazakhstan', 'Latvia', 'Austria', 'bermuda', 'Peru', 'Marshall Islands', 'Palau', 'Gambia', 'Libya', 'Nigeria', 'San Marino', 'Mali', 'Seychelles', 'Paraguay', 'Chad', 'Guadeloupe', 'curaçao', 'Nepal', 'turks and caicos islands', 'Colombia', 'Hungary', 'Denmark', 'Malaysia', 'Equatorial Guinea', 'Guatemala', 'Somalia', 'Montenegro', 'Croatia', 'Honduras', 'Netherlands', 'north macedonia', 'Liberia', 'Maldives', 'Jersey', 'Puerto Rico', 'virgin islands, british', 'Mauritania', 'South Africa', 'Tunisia', 'Spain', 'Sweden', 'French Polynesia', 'Mozambique', 'Iraq', 'cabo verde', 'Saudi Arabia', 'Azerbaijan', 'Norfolk Island', 'Benin', 'Nauru', 'Slovakia', 'Canada', 'Qatar', 'Congo', 'Guinea', 'Haiti', 'Estonia', 'Niger', 'Cameroon', 'Tajikistan', 'Andorra', 'Ecuador', 'cocos (keeling) islands', 'Singapore', 'Philippines', 'Brazil', 'Nicaragua', 'Guinea-Bissau', 'Bosnia and Herzegovina', 'Cuba', 'Vanuatu', 'brunei darussalam', 'congo', \"Korea, Democratic People's Republic of\", 'Portugal', 'fiji', 'Bangladesh', 'Morocco', 'Burundi', 'Central African Republic', 'Kiribati', 'Cambodia', 'Senegal', 'Burkina Faso', 'Pakistan', 'bonaire, sint eustatius and saba', 'Poland', 'Togo', 'Barbados', 'Greece', 'Zimbabwe', 'Panama', 'Angola', 'Jordan', 'saint helena, ascension and tristan da cunha', 'Ireland', 'Bulgaria', 'Grenada', 'Albania', 'Tonga', 'Jamaica', 'Martinique', 'Mauritius', 'Eritrea', 'Mayotte', 'Lesotho', 'réunion', 'India', 'luxembourg', 'Malta', 'France', 'Mongolia', 'Belize', 'United Kingdom', 'United Arab Emirates', 'Saint Martin (French part)', 'Norway', 'Samoa', 'Costa Rica', 'saint pierre and miquelon', 'swaziland', 'Iceland', 'Serbia', 'Trinidad and Tobago', 'Guam', 'Greenland', 'Northern Mariana Islands', \"Lao People's Democratic Republic\", 'Niue', 'Western Sahara', 'Rwanda', 'Mexico', 'Venezuela, Bolivarian Republic of', 'French Guiana', 'Syrian Arab Republic', 'American Samoa', 'Tuvalu', 'Monaco', 'saint barthélemy', 'Sao Tome and Principe', 'Namibia', 'saint lucia', 'sint maarten (dutch part)', 'falkland islands (malvinas)', 'New Zealand', 'Belarus', 'Lebanon', 'Cayman Islands', 'Thailand', 'Bolivia, Plurinational State of', 'New Caledonia', 'saint kitts and nevis', 'Japan', 'Viet Nam', 'Afghanistan', 'netherl. antilles', 'Kuwait', 'Uruguay', 'Slovenia', 'ivory coast', 'Sierra Leone', 'Faroe Islands', 'Antigua and Barbuda', 'Lithuania', 'Papua New Guinea', 'Botswana', 'Egypt', 'Aruba', 'Yemen', 'Ghana', 'Montserrat', 'Italy', 'timor-leste', 'myanmar', 'Suriname', 'Anguilla', 'Tanzania, United Republic of', 'Belgium', 'Armenia', 'Guyana', 'Germany', 'Liechtenstein']\n"
     ]
    }
   ],
   "source": [
    "import pycountry\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def token_sort_ratio_score(input_name, name):\n",
    "    score = fuzz.token_sort_ratio(input_name, name)\n",
    "    return score\n",
    "# Example list with synonyms and variations\n",
    "countries = list(country_set)\n",
    "\n",
    "# Create a list of standard country names from pycountry\n",
    "standard_countries = [country.name.lower() for country in pycountry.countries]\n",
    "\n",
    "# Function to normalize country names\n",
    "def normalize_country(name):\n",
    "    name = name.lower()\n",
    "    try:\n",
    "        # Direct lookup in pycountry\n",
    "        country = pycountry.countries.lookup(name)\n",
    "        return country.name\n",
    "    except LookupError:\n",
    "        # Fuzzy matching if direct lookup fails\n",
    "        match, score = process.extractOne(name, standard_countries)\n",
    "        if score > 80:\n",
    "            return match\n",
    "        return name\n",
    "\n",
    "# Normalize and deduplicate\n",
    "normalized_countries = [normalize_country(country) for country in countries]\n",
    "unique_countries = list(dict.fromkeys(normalized_countries))\n",
    "\n",
    "print(unique_countries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aruba', 'afghanistan', 'angola', 'anguilla', 'åland islands', 'albania', 'andorra', 'united arab emirates', 'argentina', 'armenia', 'american samoa', 'antarctica', 'french southern territories', 'antigua and barbuda', 'australia', 'austria', 'azerbaijan', 'burundi', 'belgium', 'benin', 'bonaire, sint eustatius and saba', 'burkina faso', 'bangladesh', 'bulgaria', 'bahrain', 'bahamas', 'bosnia and herzegovina', 'saint barthélemy', 'belarus', 'belize', 'bermuda', 'bolivia, plurinational state of', 'brazil', 'barbados', 'brunei darussalam', 'bhutan', 'bouvet island', 'botswana', 'central african republic', 'canada', 'cocos (keeling) islands', 'switzerland', 'chile', 'china', \"côte d'ivoire\", 'cameroon', 'congo, the democratic republic of the', 'congo', 'cook islands', 'colombia', 'comoros', 'cabo verde', 'costa rica', 'cuba', 'curaçao', 'christmas island', 'cayman islands', 'cyprus', 'czechia', 'germany', 'djibouti', 'dominica', 'denmark', 'dominican republic', 'algeria', 'ecuador', 'egypt', 'eritrea', 'western sahara', 'spain', 'estonia', 'ethiopia', 'finland', 'fiji', 'falkland islands (malvinas)', 'france', 'faroe islands', 'micronesia, federated states of', 'gabon', 'united kingdom', 'georgia', 'guernsey', 'ghana', 'gibraltar', 'guinea', 'guadeloupe', 'gambia', 'guinea-bissau', 'equatorial guinea', 'greece', 'grenada', 'greenland', 'guatemala', 'french guiana', 'guam', 'guyana', 'hong kong', 'heard island and mcdonald islands', 'honduras', 'croatia', 'haiti', 'hungary', 'indonesia', 'isle of man', 'india', 'british indian ocean territory', 'ireland', 'iran, islamic republic of', 'iraq', 'iceland', 'israel', 'italy', 'jamaica', 'jersey', 'jordan', 'japan', 'kazakhstan', 'kenya', 'kyrgyzstan', 'cambodia', 'kiribati', 'saint kitts and nevis', 'korea, republic of', 'kuwait', \"lao people's democratic republic\", 'lebanon', 'liberia', 'libya', 'saint lucia', 'liechtenstein', 'sri lanka', 'lesotho', 'lithuania', 'luxembourg', 'latvia', 'macao', 'saint martin (french part)', 'morocco', 'monaco', 'moldova, republic of', 'madagascar', 'maldives', 'mexico', 'marshall islands', 'north macedonia', 'mali', 'malta', 'myanmar', 'montenegro', 'mongolia', 'northern mariana islands', 'mozambique', 'mauritania', 'montserrat', 'martinique', 'mauritius', 'malawi', 'malaysia', 'mayotte', 'namibia', 'new caledonia', 'niger', 'norfolk island', 'nigeria', 'nicaragua', 'niue', 'netherlands', 'norway', 'nepal', 'nauru', 'new zealand', 'oman', 'pakistan', 'panama', 'pitcairn', 'peru', 'philippines', 'palau', 'papua new guinea', 'poland', 'puerto rico', \"korea, democratic people's republic of\", 'portugal', 'paraguay', 'palestine, state of', 'french polynesia', 'qatar', 'réunion', 'romania', 'russian federation', 'rwanda', 'saudi arabia', 'sudan', 'senegal', 'singapore', 'south georgia and the south sandwich islands', 'saint helena, ascension and tristan da cunha', 'svalbard and jan mayen', 'solomon islands', 'sierra leone', 'el salvador', 'san marino', 'somalia', 'saint pierre and miquelon', 'serbia', 'south sudan', 'sao tome and principe', 'suriname', 'slovakia', 'slovenia', 'sweden', 'eswatini', 'sint maarten (dutch part)', 'seychelles', 'syrian arab republic', 'turks and caicos islands', 'chad', 'togo', 'thailand', 'tajikistan', 'tokelau', 'turkmenistan', 'timor-leste', 'tonga', 'trinidad and tobago', 'tunisia', 'türkiye', 'tuvalu', 'taiwan, province of china', 'tanzania, united republic of', 'uganda', 'ukraine', 'united states minor outlying islands', 'uruguay', 'united states', 'uzbekistan', 'holy see (vatican city state)', 'saint vincent and the grenadines', 'venezuela, bolivarian republic of', 'virgin islands, british', 'virgin islands, u.s.', 'viet nam', 'vanuatu', 'wallis and futuna', 'samoa', 'yemen', 'south africa', 'zambia', 'zimbabwe']\n"
     ]
    }
   ],
   "source": [
    "print(standard_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0])\n",
    "colNum_to_colName = {i:col for i,col in enumerate(data[0])}\n",
    "print(colNum_to_colName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "customer_cmd_code_to_bvd = {}\n",
    "# with open('export.csv', mode ='r') as file:\n",
    "#     csvFile = csv.reader(file)\n",
    "#     data = list(csvFile)\n",
    "\n",
    "for idx, arr in enumerate(data[1:]):\n",
    "    tax = set()\n",
    "    for i in range(24, 27):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            # print(type(arr[i]))\n",
    "            tax.add(arr[i])\n",
    "            # print(tax)\n",
    "\n",
    "    if customer_cmd_code_to_bvd.get(arr[2]) is None:\n",
    "        customer_cmd_code_to_bvd[arr[2]] = tax\n",
    "    else:\n",
    "        customer_cmd_code_to_bvd[arr[2]] = customer_cmd_code_to_bvd[arr[2]].union(tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_bvd_num = 0\n",
    "bvd_num_exists = 0\n",
    "more_than_one_bvd_num = 0\n",
    "# count = 10\n",
    "for key, value in customer_cmd_code_to_bvd.items():\n",
    "    if len(value) == 0:\n",
    "        no_bvd_num += 1\n",
    "    else:\n",
    "        bvd_num_exists += 1\n",
    "    if len(value) > 1:\n",
    "        more_than_one_bvd_num += 1\n",
    "    # count -= 1\n",
    "    # if count == 0:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(more_than_one_bvd_num)\n",
    "print(no_bvd_num)\n",
    "print(bvd_num_exists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for now generating 3 types of corpus for comparison:\n",
    "1. set of tax number\n",
    "2. set of bvd number\n",
    "3. dict of customer_cmd_code to list of entries corresponding to the same customer_cmd_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stop_words = {'llp', 'ltd', 'llc', 'plc', 'inc', 'corp', 'nv', 'group', 'gmbh', 'sa', 'company', 'corporation', 'limited'}\n",
    "delimiters = {\".\", \",\", \"-\", \"_\", \"'\", \"&\", \"/\", \"\\\\\", \":\", \";\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \" \"}\n",
    "def split_company_name(name):\n",
    "    pattern = '|'.join(map(re.escape, delimiters))\n",
    "    words = re.split(pattern, name)\n",
    "    return [word for word in words if word]\n",
    "\n",
    "def lowercase_company_name(name):\n",
    "    return name.lower()\n",
    "\n",
    "# List of common delimiters\n",
    "def remove_stop_words(words):\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "def clean_company_name(trading_name):\n",
    "    # Lowercase the company name\n",
    "    trading_name = lowercase_company_name(trading_name)\n",
    "    # Split the company name into words\n",
    "    words = split_company_name(trading_name)\n",
    "    # Remove stop words\n",
    "    clean_name = remove_stop_words(words)\n",
    "    return clean_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_number_matches = 5\n",
    "from time import time\n",
    "from rapidfuzz import fuzz, process\n",
    "import heapq\n",
    "def sorted_tokens(name):\n",
    "    return \" \".join(sorted(name.split()))\n",
    "\n",
    "#calculates the minimum number of edits (insertions, deletions, substitutions) needed to transform one string into another.\n",
    "#For typos or minor spelling variations\n",
    "def levenshtein_matching_score(input_name, name):\n",
    "    levenshtein_matching_score = fuzz.ratio(input_name, name)\n",
    "    return levenshtein_matching_score\n",
    "\n",
    "#split strings into tokens (words) and compare the intersection and order of these tokens. This is useful for handling different word orders or missing words in one string.\n",
    "def token_set_matching_score(input_name, name):\n",
    "    token_set_matching_score = fuzz.token_set_ratio(input_name, name)\n",
    "    return token_set_matching_score\n",
    "\n",
    "#For situations with extra content or partial matches:\n",
    "def partial_matching_score(input_name, name):\n",
    "    partial_matching_score = fuzz.partial_token_set_ratio(input_name, name)\n",
    "    return partial_matching_score\n",
    "\n",
    "#focus on finding matching subsequences within strings. This is beneficial when comparing strings with extra content or typos.\n",
    "#For typos or minor spelling variations\n",
    "def substring_matching_score(input_name, name):\n",
    "    substring_matching_score = fuzz.partial_ratio(input_name, name)\n",
    "    return substring_matching_score\n",
    "\n",
    "#split strings into tokens (words) and compare the intersection and order of these tokens. This is useful for handling different word orders or missing words in one string.\n",
    "def token_sort_ratio_score(input_name, name):\n",
    "    score = fuzz.token_sort_ratio(input_name, name)\n",
    "    return score\n",
    "# Matching\n",
    "\n",
    "def match_name_top_matches(input_name, corpus):\n",
    "    input_name = clean_company_name(input_name)\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    top_matches = []\n",
    "    heapq.heapify(top_matches)\n",
    "    similarity_measures = { \n",
    "        \"levenshtein_matching_score\" : (0, levenshtein_matching_score),\n",
    "        \"token_set_matching_score\" : (1, token_set_matching_score),\n",
    "        \"substring_matching_score\" : (1, substring_matching_score),\n",
    "        \"partial_matching_score\" : (1, partial_matching_score),\n",
    "        \"token_sort_ratio_score\" : (0, token_sort_ratio_score)\n",
    "    }\n",
    "    print(\"Length of corpus: \", len(corpus))\n",
    "    s_time = time()\n",
    "    for customer_info in corpus:\n",
    "        name = customer_info[4]\n",
    "        name = clean_company_name(name)\n",
    "        num_measures = 0\n",
    "        total_score = 0\n",
    "        for func_key, function_check in similarity_measures.items():\n",
    "            check, func = function_check\n",
    "            s_func_time = time()\n",
    "            \n",
    "            if check:\n",
    "                score = func(input_name, name)\n",
    "                total_score += score\n",
    "                num_measures +=1\n",
    "            if num_measures == 0:\n",
    "                combined_score = 0\n",
    "            else:\n",
    "                combined_score = total_score / num_measures\n",
    "        if len(top_matches) < max_number_matches:\n",
    "            heapq.heappush(top_matches, (combined_score, customer_info))\n",
    "        else:\n",
    "            heapq.heappushpop(top_matches, (combined_score, customer_info))\n",
    "        if combined_score > best_score:\n",
    "            best_score = combined_score\n",
    "            best_match = customer_info\n",
    "    e_time = time()\n",
    "    print(\"Time taken: \", e_time - s_time)\n",
    "    return best_match, best_score, top_matches\n",
    "\n",
    "def match_name(input_name, corpus):\n",
    "    input_name = clean_company_name(input_name)\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    top_matches = []\n",
    "    # heapq.heapify(top_matches)\n",
    "    similarity_measures = { \n",
    "        \"levenshtein_matching_score\" : (0, levenshtein_matching_score),\n",
    "        \"token_set_matching_score\" : (1, token_set_matching_score),\n",
    "        \"substring_matching_score\" : (1, substring_matching_score),\n",
    "        \"partial_matching_score\" : (1, partial_matching_score),\n",
    "        \"token_sort_ratio_score\" : (0, token_sort_ratio_score)\n",
    "    }\n",
    "    for customer_info in corpus:\n",
    "        name = customer_info[4]\n",
    "        name = clean_company_name(name)\n",
    "        num_measures = 0\n",
    "        total_score = 0\n",
    "        for function_check in similarity_measures.values():\n",
    "            check, func = function_check\n",
    "            if check:\n",
    "                score = func(input_name, name)\n",
    "                total_score += score\n",
    "                num_measures +=1\n",
    "            if num_measures == 0:\n",
    "                combined_score = 0\n",
    "            else:\n",
    "                combined_score = total_score / num_measures\n",
    "        # if len(top_matches) < max_number_matches:\n",
    "        #     heapq.heappush(top_matches, (combined_score, customer_info))\n",
    "        # else:\n",
    "        #     heapq.heappushpop(top_matches, (combined_score, customer_info))\n",
    "        if combined_score > best_score:\n",
    "            best_score = combined_score\n",
    "            best_match = customer_info\n",
    "    \n",
    "    return best_match, best_score, top_matches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fc9b8508430>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/k.abhishek/Documents/customer_clusters/.conda/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "#preparing data for testing\n",
    "corpus_ratio = 0.9\n",
    "\n",
    "num_customer_corpus = int(len(data) * corpus_ratio)\n",
    "\n",
    "testing_customer_corpus = []\n",
    "\n",
    "unique_tax_numbers = {}\n",
    "unique_bvd_numbers = {}\n",
    "corpus_customer_cmd_code = {}\n",
    "corpus_legal_cluster_id = {}\n",
    "country_wise_corpus = {}\n",
    "for idx, arr in enumerate(data[1:num_customer_corpus]):\n",
    "    country_name = arr[16].lower()\n",
    "    for i in range(24, 27):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            if unique_bvd_numbers.get(arr[i].lower()):\n",
    "                unique_bvd_numbers[arr[i].lower()].append(arr)\n",
    "            else:\n",
    "                unique_bvd_numbers[arr[i].lower()] = [arr]\n",
    "            # unique_bvd_numbers[arr[i]] = arr\n",
    "    for i in range(27, 33):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            if unique_tax_numbers.get(arr[i].lower()):\n",
    "                unique_tax_numbers[arr[i].lower()].append(arr)\n",
    "            else:\n",
    "                unique_tax_numbers[arr[i].lower()] = [arr]\n",
    "            # unique_tax_numbers[arr[i]] = arr\n",
    "\n",
    "    if country_wise_corpus.get(country_name):\n",
    "        country_wise_corpus[country_name].append(arr)\n",
    "    else:\n",
    "        country_wise_corpus[country_name] = [arr]\n",
    "    \n",
    "    customer_cmd_code = arr[2].lower()\n",
    "    if corpus_customer_cmd_code.get(customer_cmd_code):\n",
    "        corpus_customer_cmd_code[customer_cmd_code].append(arr)\n",
    "    else:    \n",
    "        corpus_customer_cmd_code[customer_cmd_code] = [arr]\n",
    "    \n",
    "    legal_cluster_id = arr[1].lower()\n",
    "    if corpus_legal_cluster_id.get(legal_cluster_id):\n",
    "        corpus_legal_cluster_id[legal_cluster_id].append(arr)\n",
    "    else:\n",
    "        corpus_legal_cluster_id[legal_cluster_id] = [arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tax_numbers(arr):\n",
    "    unique_tax_numbers = set()\n",
    "    for i in range(27, 33):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            unique_tax_numbers.add(arr[i].lower())\n",
    "    return unique_tax_numbers\n",
    "\n",
    "def extract_bvd_numbers(arr):\n",
    "    unique_bvd_numbers = set()\n",
    "    for i in range(24, 27):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            unique_bvd_numbers.add(arr[i].lower())\n",
    "    return unique_bvd_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def match_tax(arr):\n",
    "    tax = extract_tax_numbers(arr)\n",
    "    for tax_num in tax:\n",
    "        if tax_num in unique_tax_numbers:\n",
    "            return unique_tax_numbers[tax_num]\n",
    "    return None\n",
    "\n",
    "def match_bvd(arr):\n",
    "    bvd = extract_bvd_numbers(arr)\n",
    "    for bvd_num in bvd:\n",
    "        if bvd_num in unique_bvd_numbers:\n",
    "            return unique_bvd_numbers[bvd_num]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_top_matches(top_matches):\n",
    "    matches = {}\n",
    "    sorted_matches = sorted(top_matches, key=lambda x: x[0], reverse=True)\n",
    "    rank = 1\n",
    "    for idx, match in enumerate(sorted_matches):\n",
    "        score = match[0]\n",
    "        match_info = {\n",
    "            \"score\" : score,\n",
    "            \"customer_info\" : match[1]\n",
    "        }\n",
    "        matches[rank].append(match_info)\n",
    "        rank += 1\n",
    "        # flag = False\n",
    "        # legal_cluster_id = match[1][1]\n",
    "        # # print(match)\n",
    "        # # print(legal_cluster_id)\n",
    "        # for r, existing_match in matches.items():\n",
    "        #     if existing_match[0][\"customer_info\"][1] == legal_cluster_id:\n",
    "        #         matches[r].append(match_info)\n",
    "        #         flag = True\n",
    "        #         break\n",
    "        # if not flag:\n",
    "        #     matches[rank] = [match_info]\n",
    "        #     rank += 1\n",
    "    # print(matches)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "success = 0\n",
    "failure = 0\n",
    "not_applicable = 0\n",
    "result = {}\n",
    "for arr in tqdm(data[num_customer_corpus:]):\n",
    "    customer_cmd_code = arr[2].lower()\n",
    "    # print(customer_cmd_code)\n",
    "    legal_cluster_id = arr[1].lower()\n",
    "    #checking if the test customer is in the corpus for the comparison\n",
    "    if legal_cluster_id in corpus_legal_cluster_id.keys():\n",
    "        matches = {}\n",
    "        #tax matching\n",
    "        tax_match = match_tax(arr)\n",
    "        if tax_match:\n",
    "            success += 1\n",
    "            matches[1] = tax_match\n",
    "            result[str(arr)] = matches\n",
    "            continue\n",
    "        #bvd matching\n",
    "        bvd_match = match_bvd(arr)\n",
    "        if bvd_match:\n",
    "            success += 1\n",
    "            matches[1] = bvd_match\n",
    "            result[str(arr)] = matches\n",
    "            continue\n",
    "\n",
    "        #trading name matching after country filtering \n",
    "        country_name = arr[16].lower()\n",
    "        #filtering by country and hence reducing our search space\n",
    "        if country_wise_corpus.get(country_name) is None:\n",
    "            not_applicable += 1\n",
    "            continue\n",
    "        filtered_corpus = country_wise_corpus[country_name]\n",
    "        print(country_name, len(filtered_corpus))\n",
    "        company_name = arr[4]\n",
    "        cleaned_company_name = clean_company_name(company_name)\n",
    "        best_match, best_score, top_matches = match_name(cleaned_company_name, filtered_corpus)\n",
    "        # reformatted_top_matches = reformat_top_matches(top_matches)\n",
    "        if legal_cluster_id == best_match[1]:\n",
    "            success +=1\n",
    "        else:\n",
    "            failure +=1\n",
    "        # if reformatted_top_matches.get(1):\n",
    "        #     # print(reformatted_top_matches[1][0]['customer_info'][1])\n",
    "        #     if legal_cluster_id == reformatted_top_matches[1][0]['customer_info'][1]:\n",
    "        #         success +=1\n",
    "        #     else:\n",
    "        #         failure +=1\n",
    "        \n",
    "        # matches = reformat_top_matches(top_matches)\n",
    "        # result[str(arr)] = matches\n",
    "        \n",
    "    else:\n",
    "        not_applicable +=1    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('result_match_tax_bvd_name_country-2-3-4.json', 'w') as f:\n",
    "    json.dump(result, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(success, failure, not_applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success/(failure + success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success + failure + not_applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
