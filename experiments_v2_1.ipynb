{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file = \"/Users/k.abhishek/Documents/customer_clusters/customer_onboard_data.xlsx\"\n",
    "df = pd.read_excel(file)\n",
    "print(df.columns)\n",
    "colNum_to_colName = {i:col for i,col in enumerate(df.columns)}\n",
    "print(colNum_to_colName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index(['SITE_CLUSTER_ID', 'LEGAL_CLUSTER_ID', 'customer_cmd_code',\n",
    "       'customer_role_type', 'trading_name', 'street_no', 'address_line1',\n",
    "       'pobox', 'address_line2', 'address_line3', 'district', 'city',\n",
    "       'postal_code', 'state_code', 'state_name', 'country_code',\n",
    "       'country_name', 'phone_type', 'isd_country_code', 'isd_dialing_code',\n",
    "       'extension_number', 'phone_num', 'create_time', 'customer_cmd_code.1',\n",
    "       'BVD', 'BVD_HQ', 'BVD_GUO', 'TAXNO1', 'TAXNO2', 'TAXNO3', 'TAXNO4',\n",
    "       'TAXNO5', 'VATREG'],\n",
    "      dtype='object')\n",
    "{0: 'SITE_CLUSTER_ID', 1: 'LEGAL_CLUSTER_ID', 2: 'customer_cmd_code', 3: 'customer_role_type', 4: 'trading_name', 5: 'street_no', 6: 'address_line1', 7: 'pobox', 8: 'address_line2', 9: 'address_line3', 10: 'district', 11: 'city', 12: 'postal_code', 13: 'state_code', 14: 'state_name', 15: 'country_code', 16: 'country_name', 17: 'phone_type', 18: 'isd_country_code', 19: 'isd_dialing_code', 20: 'extension_number', 21: 'phone_num', 22: 'create_time', 23: 'customer_cmd_code.1', 24: 'BVD', 25: 'BVD_HQ', 26: 'BVD_GUO', 27: 'TAXNO1', 28: 'TAXNO2', 29: 'TAXNO3', 30: 'TAXNO4', 31: 'TAXNO5', 32: 'VATREG'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from csv\n",
    "import csv\n",
    "\n",
    "with open('export_all_v2.csv', mode ='r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    data = list(csvFile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_set = {}\n",
    "for idx, arr in enumerate(data[1:]):\n",
    "    country_code = arr[15].lower()\n",
    "    country_name = arr[16].lower()\n",
    "    if country_code not in country_set:\n",
    "        country_set[country_code] = set([country_name])\n",
    "    else:\n",
    "        country_set[country_code].add(country_name)\n",
    "len(country_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bj': {'benin'},\n",
       " 'gh': {'ghana'},\n",
       " 'ne': {'niger'},\n",
       " 'ng': {'nigeria'},\n",
       " 'tg': {'togo'},\n",
       " 'dk': {'denmark'},\n",
       " 'se': {'sweden'},\n",
       " 'lu': {'luxemburg'},\n",
       " 'be': {'belgium'},\n",
       " 'is': {'iceland'},\n",
       " 'at': {'austria'},\n",
       " 'de': {'germany'},\n",
       " 'nl': {'netherlands'},\n",
       " 'ch': {'switzerland'},\n",
       " 'li': {'liechtenstein'},\n",
       " 'bw': {'botswana'},\n",
       " 'km': {'comoro islands'},\n",
       " 'ls': {'lesotho'},\n",
       " 'mg': {'madagascar'},\n",
       " 'mw': {'malawi'},\n",
       " 'mu': {'mauritius'},\n",
       " 'mz': {'mozambique'},\n",
       " 'na': {'namibia'},\n",
       " 'zw': {'zimbabwe'},\n",
       " 'za': {'south africa'},\n",
       " 'zm': {'zambia'},\n",
       " 'sz': {'swaziland'},\n",
       " 'sc': {'seychelles'},\n",
       " 'ar': {'argentina'},\n",
       " 'br': {'brazil'},\n",
       " 'py': {'paraguay'},\n",
       " 'uy': {'uruguay'},\n",
       " 'no': {'norway'},\n",
       " 'fi': {'finland'},\n",
       " 'al': {'albania'},\n",
       " 'bg': {'bulgaria'},\n",
       " 'ad': {'andorra'},\n",
       " 'fr': {'france'},\n",
       " 'gi': {'gibraltar'},\n",
       " 'gr': {'greece'},\n",
       " 'hu': {'hungary'},\n",
       " 'ie': {'ireland'},\n",
       " 'it': {'italy'},\n",
       " 'mt': {'malta'},\n",
       " 'mc': {'monaco'},\n",
       " 'pl': {'poland'},\n",
       " 'pt': {'portugal'},\n",
       " 'ro': {'romania'},\n",
       " 'es': {'spain'},\n",
       " 'tr': {'turkey'},\n",
       " 'gb': {'united kingdom'},\n",
       " 'cy': {'cyprus'},\n",
       " 'ee': {'estonia'},\n",
       " 'lv': {'latvia'},\n",
       " 'lt': {'lithuania'},\n",
       " 'hr': {'croatia'},\n",
       " 'si': {'slovenia'},\n",
       " 'ba': {'bosnia and herzegovina'},\n",
       " 'mk': {'macedonia'},\n",
       " 'gg': {'guernsey'},\n",
       " 'je': {'jersey'},\n",
       " 'sm': {'san marino'},\n",
       " 'cz': {'czech republic'},\n",
       " 'sk': {'slovakia'},\n",
       " 'am': {'armenia'},\n",
       " 'by': {'belarus'},\n",
       " 'md': {'moldova'},\n",
       " 'ru': {'russia'},\n",
       " 'ua': {'ukraine'},\n",
       " 'ge': {'georgia'},\n",
       " 'az': {'azerbaijan'},\n",
       " 'me': {'montenegro'},\n",
       " 'rs': {'serbia'},\n",
       " 'dz': {'algeria'},\n",
       " 'eg': {'egypt'},\n",
       " 'gm': {'gambia'},\n",
       " 'gn': {'guinea'},\n",
       " 'ci': {'ivory coast'},\n",
       " 'lr': {'liberia'},\n",
       " 'ly': {'libya'},\n",
       " 'ml': {'mali'},\n",
       " 'mr': {'mauritania'},\n",
       " 'ma': {'morocco'},\n",
       " 'sn': {'senegal'},\n",
       " 'sl': {'sierra leone'},\n",
       " 're': {'reunion'},\n",
       " 'tn': {'tunisia'},\n",
       " 'bf': {'burkina faso'},\n",
       " 'gw': {'guinea-bissau'},\n",
       " 'cv': {'cape verde island'},\n",
       " 'bs': {'bahamas'},\n",
       " 'bb': {'barbados'},\n",
       " 'bm': {'bermuda island'},\n",
       " 'bo': {'bolivia'},\n",
       " 'yt': {'mayotte'},\n",
       " 'sh': {'saint helena'},\n",
       " 'ca': {'canada'},\n",
       " 'cl': {'chile'},\n",
       " 'co': {'colombia'},\n",
       " 'cr': {'costa rica'},\n",
       " 'cu': {'cuba'},\n",
       " 'do': {'dominican republic'},\n",
       " 'ec': {'ecuador'},\n",
       " 'sv': {'el salvador'},\n",
       " 'fk': {'falkland island'},\n",
       " 'gt': {'guatemala'},\n",
       " 'gy': {'guyana'},\n",
       " 'sr': {'suriname'},\n",
       " 'gf': {'french guiana'},\n",
       " 'ht': {'haiti'},\n",
       " 'hn': {'honduras'},\n",
       " 'bz': {'belize'},\n",
       " 'jm': {'jamaica'},\n",
       " 'mx': {'mexico'},\n",
       " 'ni': {'nicaragua'},\n",
       " 'pa': {'panama'},\n",
       " 'pe': {'peru'},\n",
       " 'pr': {'puerto rico'},\n",
       " 'tt': {'trinidad and tobago'},\n",
       " 'us': {'united states'},\n",
       " 've': {'venezuela'},\n",
       " 'an': {'netherl. antilles'},\n",
       " 'gp': {'guadeloupe'},\n",
       " 'dm': {'dominica'},\n",
       " 'mq': {'martinique'},\n",
       " 'vc': {'saint vincent and the grenadines'},\n",
       " 'kn': {'st kitts-nevis'},\n",
       " 'ai': {'anguilla'},\n",
       " 'lc': {'st lucia'},\n",
       " 'vg': {'virgin islands (br.)'},\n",
       " 'vi': {'virgin islands (us)'},\n",
       " 'ky': {'cayman islands'},\n",
       " 'tc': {'turks and caicos'},\n",
       " 'aw': {'aruba'},\n",
       " 'cw': {'curacao'},\n",
       " 'il': {'israel'},\n",
       " 'lb': {'lebanon'},\n",
       " 'sy': {'syria'},\n",
       " 'tm': {'turkmenistan'},\n",
       " 'uz': {'uzbekistan'},\n",
       " 'kz': {'kazakhstan'},\n",
       " 'kg': {'kyrgyzstan'},\n",
       " 'tj': {'tajikistan'},\n",
       " 'gu': {'guam'},\n",
       " 'fo': {'faroe islands'},\n",
       " 'cm': {'cameroon'},\n",
       " 'bi': {'burundi'},\n",
       " 'cf': {'central african republic'},\n",
       " 'td': {'chad'},\n",
       " 'cg': {'congo'},\n",
       " 'cd': {'congo, dem. rep. of'},\n",
       " 'et': {'ethiopia'},\n",
       " 'dj': {'djibouti'},\n",
       " 'ga': {'gabon'},\n",
       " 'ke': {'kenya'},\n",
       " 'ao': {'angola'},\n",
       " 'rw': {'rwanda'},\n",
       " 'so': {'somalia'},\n",
       " 'sd': {'sudan'},\n",
       " 'tz': {'tanzania'},\n",
       " 'ug': {'uganda'},\n",
       " 'gq': {'equatorial guinea'},\n",
       " 'er': {'eritrea'},\n",
       " 'ss': {'south sudan'},\n",
       " 'af': {'afghanistan'},\n",
       " 'bh': {'bahrain'},\n",
       " 'st': {'sao tome and principe'},\n",
       " 'lk': {'sri lanka'},\n",
       " 'in': {'india'},\n",
       " 'ir': {'iran'},\n",
       " 'iq': {'iraq'},\n",
       " 'jo': {'jordan'},\n",
       " 'kw': {'kuwait'},\n",
       " 'om': {'oman'},\n",
       " 'mv': {'maldives'},\n",
       " 'np': {'nepal'},\n",
       " 'pk': {'pakistan'},\n",
       " 'qa': {'qatar'},\n",
       " 'sa': {'saudi arabia'},\n",
       " 'ae': {'united arab emirates'},\n",
       " 'ye': {'yemen'},\n",
       " 'bd': {'bangladesh'},\n",
       " 'bt': {'bhutan'},\n",
       " 'au': {'australia'},\n",
       " 'pg': {'papua new guinea'},\n",
       " 'nz': {'new zealand'},\n",
       " 'fj': {'fiji islands'},\n",
       " 'fm': {'fed st of micronesia'},\n",
       " 'nc': {'new caledonia'},\n",
       " 'pf': {'french polynesia'},\n",
       " 'wf': {'wallis & futuna'},\n",
       " 'ws': {'samoa'},\n",
       " 'sb': {'solomon islands'},\n",
       " 'vu': {'vanuatu'},\n",
       " 'as': {'american samoa'},\n",
       " 'mh': {'marshall islands'},\n",
       " 'ck': {'cook islands'},\n",
       " 'to': {'tonga'},\n",
       " 'ki': {'kiribati'},\n",
       " 'tl': {'timor leste'},\n",
       " 'bn': {'brunei'},\n",
       " 'mm': {'myanmar (burma)'},\n",
       " 'kh': {'cambodia'},\n",
       " 'cn': {'china'},\n",
       " 'tw': {'taiwan china'},\n",
       " 'hk': {'hong kong china'},\n",
       " 'id': {'indonesia'},\n",
       " 'jp': {'japan'},\n",
       " 'kp': {'north korea'},\n",
       " 'kr': {'korea, south'},\n",
       " 'la': {'laos'},\n",
       " 'my': {'malaysia'},\n",
       " 'mn': {'mongolia'},\n",
       " 'ph': {'philippines'},\n",
       " 'mo': {'macao china'},\n",
       " 'sg': {'singapore'},\n",
       " 'th': {'thailand'},\n",
       " 'vn': {'vietnam'},\n",
       " 'sx': {'sint maarten'},\n",
       " 'bq': {'bonaire sint eustatius and saba'},\n",
       " 'ag': {'antigua and barbuda'},\n",
       " 'gd': {'grenada'},\n",
       " 'pm': {'st pierre and miquelon'},\n",
       " 'gl': {'greenland'},\n",
       " 'im': {'isle of man'},\n",
       " 'ms': {'montserrat'},\n",
       " 'mp': {'northern mariana islands'},\n",
       " 'pw': {'palau'},\n",
       " 'eh': {'western sahara'},\n",
       " 'mf': {'saint martin (french part)'},\n",
       " 'nf': {'norfolk island'},\n",
       " 'tv': {'tuvalu'},\n",
       " 'nr': {'nauru'},\n",
       " 'bl': {'saint barthelemy'},\n",
       " 'nu': {'niue'}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "delimiters = {\".\", \",\", \"-\", \"_\", \"'\", \"&\", \"/\", \"\\\\\", \":\", \";\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \" \"}\n",
    "def split_company_name(name):\n",
    "    pattern = '|'.join(map(re.escape, delimiters))\n",
    "    words = re.split(pattern, name)\n",
    "    return [word for word in words if word]\n",
    "\n",
    "def lowercase_company_name(name):\n",
    "    return name.lower()\n",
    "\n",
    "def clean_country_name(trading_name):\n",
    "    # Lowercase the company name\n",
    "    trading_name = lowercase_company_name(trading_name)\n",
    "    # Split the company name into words\n",
    "    words = split_company_name(trading_name)\n",
    "    # Remove stop words\n",
    "    clean_name = \" \".join(words)\n",
    "    return clean_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in pycountry.countries:\n",
    "    print(country.alpha_2, country.alpha_3, country.name, country.numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0])\n",
    "colNum_to_colName = {i:col for i,col in enumerate(data[0])}\n",
    "print(colNum_to_colName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "customer_cmd_code_to_bvd = {}\n",
    "# with open('export.csv', mode ='r') as file:\n",
    "#     csvFile = csv.reader(file)\n",
    "#     data = list(csvFile)\n",
    "\n",
    "for idx, arr in enumerate(data[1:]):\n",
    "    tax = set()\n",
    "    for i in range(24, 27):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            # print(type(arr[i]))\n",
    "            tax.add(arr[i])\n",
    "            # print(tax)\n",
    "\n",
    "    if customer_cmd_code_to_bvd.get(arr[2]) is None:\n",
    "        customer_cmd_code_to_bvd[arr[2]] = tax\n",
    "    else:\n",
    "        customer_cmd_code_to_bvd[arr[2]] = customer_cmd_code_to_bvd[arr[2]].union(tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_bvd_num = 0\n",
    "bvd_num_exists = 0\n",
    "more_than_one_bvd_num = 0\n",
    "# count = 10\n",
    "for key, value in customer_cmd_code_to_bvd.items():\n",
    "    if len(value) == 0:\n",
    "        no_bvd_num += 1\n",
    "    else:\n",
    "        bvd_num_exists += 1\n",
    "    if len(value) > 1:\n",
    "        more_than_one_bvd_num += 1\n",
    "    # count -= 1\n",
    "    # if count == 0:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(more_than_one_bvd_num)\n",
    "print(no_bvd_num)\n",
    "print(bvd_num_exists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for now generating 3 types of corpus for comparison:\n",
    "1. set of tax number\n",
    "2. set of bvd number\n",
    "3. dict of customer_cmd_code to list of entries corresponding to the same customer_cmd_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stop_words = {'llp', 'ltd', 'llc', 'plc', 'inc', 'corp', 'nv', 'group', 'gmbh', 'sa', 'company', 'corporation', 'limited'}\n",
    "delimiters = {\".\", \",\", \"-\", \"_\", \"'\", \"&\", \"/\", \"\\\\\", \":\", \";\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \" \"}\n",
    "def split_company_name(name):\n",
    "    pattern = '|'.join(map(re.escape, delimiters))\n",
    "    words = re.split(pattern, name)\n",
    "    return [word for word in words if word]\n",
    "\n",
    "def lowercase_company_name(name):\n",
    "    return name.lower()\n",
    "\n",
    "# List of common delimiters\n",
    "def remove_stop_words(words):\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "def clean_company_name(trading_name):\n",
    "    # Lowercase the company name\n",
    "    trading_name = lowercase_company_name(trading_name)\n",
    "    # Split the company name into words\n",
    "    words = split_company_name(trading_name)\n",
    "    # Remove stop words\n",
    "    clean_name = remove_stop_words(words)\n",
    "    return clean_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_number_matches = 5\n",
    "from time import time\n",
    "from rapidfuzz import fuzz, process\n",
    "import heapq\n",
    "def sorted_tokens(name):\n",
    "    return \" \".join(sorted(name.split()))\n",
    "\n",
    "#calculates the minimum number of edits (insertions, deletions, substitutions) needed to transform one string into another.\n",
    "#For typos or minor spelling variations\n",
    "def levenshtein_matching_score(input_name, name):\n",
    "    levenshtein_matching_score = fuzz.ratio(input_name, name)\n",
    "    return levenshtein_matching_score\n",
    "\n",
    "#split strings into tokens (words) and compare the intersection and order of these tokens. This is useful for handling different word orders or missing words in one string.\n",
    "def token_set_matching_score(input_name, name):\n",
    "    token_set_matching_score = fuzz.token_set_ratio(input_name, name)\n",
    "    return token_set_matching_score\n",
    "\n",
    "#For situations with extra content or partial matches:\n",
    "def partial_matching_score(input_name, name):\n",
    "    partial_matching_score = fuzz.partial_token_set_ratio(input_name, name)\n",
    "    return partial_matching_score\n",
    "\n",
    "#focus on finding matching subsequences within strings. This is beneficial when comparing strings with extra content or typos.\n",
    "#For typos or minor spelling variations\n",
    "def substring_matching_score(input_name, name):\n",
    "    substring_matching_score = fuzz.partial_ratio(input_name, name)\n",
    "    return substring_matching_score\n",
    "\n",
    "#split strings into tokens (words) and compare the intersection and order of these tokens. This is useful for handling different word orders or missing words in one string.\n",
    "def token_sort_ratio_score(input_name, name):\n",
    "    score = fuzz.token_sort_ratio(input_name, name)\n",
    "    return score\n",
    "# Matching\n",
    "\n",
    "def match_name_top_matches(input_name, corpus):\n",
    "    input_name = clean_company_name(input_name)\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    top_matches = []\n",
    "    heapq.heapify(top_matches)\n",
    "    similarity_measures = { \n",
    "        \"levenshtein_matching_score\" : (0, levenshtein_matching_score),\n",
    "        \"token_set_matching_score\" : (1, token_set_matching_score),\n",
    "        \"substring_matching_score\" : (1, substring_matching_score),\n",
    "        \"partial_matching_score\" : (1, partial_matching_score),\n",
    "        \"token_sort_ratio_score\" : (0, token_sort_ratio_score)\n",
    "    }\n",
    "    print(\"Length of corpus: \", len(corpus))\n",
    "    s_time = time()\n",
    "    for customer_info in corpus:\n",
    "        name = customer_info[4]\n",
    "        name = clean_company_name(name)\n",
    "        num_measures = 0\n",
    "        total_score = 0\n",
    "        for func_key, function_check in similarity_measures.items():\n",
    "            check, func = function_check\n",
    "            s_func_time = time()\n",
    "            \n",
    "            if check:\n",
    "                score = func(input_name, name)\n",
    "                total_score += score\n",
    "                num_measures +=1\n",
    "            if num_measures == 0:\n",
    "                combined_score = 0\n",
    "            else:\n",
    "                combined_score = total_score / num_measures\n",
    "        if len(top_matches) < max_number_matches:\n",
    "            heapq.heappush(top_matches, (combined_score, customer_info))\n",
    "        else:\n",
    "            heapq.heappushpop(top_matches, (combined_score, customer_info))\n",
    "        if combined_score > best_score:\n",
    "            best_score = combined_score\n",
    "            best_match = customer_info\n",
    "    e_time = time()\n",
    "    print(\"Time taken: \", e_time - s_time)\n",
    "    return best_match, best_score, top_matches\n",
    "\n",
    "def match_name(input_name, corpus):\n",
    "    input_name = clean_company_name(input_name)\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    top_matches = []\n",
    "    # heapq.heapify(top_matches)\n",
    "    similarity_measures = { \n",
    "        \"levenshtein_matching_score\" : (0, levenshtein_matching_score),\n",
    "        \"token_set_matching_score\" : (1, token_set_matching_score),\n",
    "        \"substring_matching_score\" : (1, substring_matching_score),\n",
    "        \"partial_matching_score\" : (1, partial_matching_score),\n",
    "        \"token_sort_ratio_score\" : (0, token_sort_ratio_score)\n",
    "    }\n",
    "    for customer_info in corpus:\n",
    "        name = customer_info[4]\n",
    "        name = clean_company_name(name)\n",
    "        num_measures = 0\n",
    "        total_score = 0\n",
    "        for function_check in similarity_measures.values():\n",
    "            check, func = function_check\n",
    "            if check:\n",
    "                score = func(input_name, name)\n",
    "                total_score += score\n",
    "                num_measures +=1\n",
    "            if num_measures == 0:\n",
    "                combined_score = 0\n",
    "            else:\n",
    "                combined_score = total_score / num_measures\n",
    "        # if len(top_matches) < max_number_matches:\n",
    "        #     heapq.heappush(top_matches, (combined_score, customer_info))\n",
    "        # else:\n",
    "        #     heapq.heappushpop(top_matches, (combined_score, customer_info))\n",
    "        if combined_score > best_score:\n",
    "            best_score = combined_score\n",
    "            best_match = customer_info\n",
    "    \n",
    "    return best_match, best_score, top_matches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fc9b8508430>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/k.abhishek/Documents/customer_clusters/.conda/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "#preparing data for testing\n",
    "corpus_ratio = 0.9\n",
    "\n",
    "num_customer_corpus = int(len(data) * corpus_ratio)\n",
    "\n",
    "testing_customer_corpus = []\n",
    "\n",
    "unique_tax_numbers = {}\n",
    "unique_bvd_numbers = {}\n",
    "corpus_customer_cmd_code = {}\n",
    "corpus_legal_cluster_id = {}\n",
    "country_wise_corpus = {}\n",
    "for idx, arr in enumerate(data[1:num_customer_corpus]):\n",
    "    country_name = arr[16].lower()\n",
    "    for i in range(24, 27):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            if unique_bvd_numbers.get(arr[i].lower()):\n",
    "                unique_bvd_numbers[arr[i].lower()].append(arr)\n",
    "            else:\n",
    "                unique_bvd_numbers[arr[i].lower()] = [arr]\n",
    "            # unique_bvd_numbers[arr[i]] = arr\n",
    "    for i in range(27, 33):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            if unique_tax_numbers.get(arr[i].lower()):\n",
    "                unique_tax_numbers[arr[i].lower()].append(arr)\n",
    "            else:\n",
    "                unique_tax_numbers[arr[i].lower()] = [arr]\n",
    "            # unique_tax_numbers[arr[i]] = arr\n",
    "\n",
    "    if country_wise_corpus.get(country_name):\n",
    "        country_wise_corpus[country_name].append(arr)\n",
    "    else:\n",
    "        country_wise_corpus[country_name] = [arr]\n",
    "    \n",
    "    customer_cmd_code = arr[2].lower()\n",
    "    if corpus_customer_cmd_code.get(customer_cmd_code):\n",
    "        corpus_customer_cmd_code[customer_cmd_code].append(arr)\n",
    "    else:    \n",
    "        corpus_customer_cmd_code[customer_cmd_code] = [arr]\n",
    "    \n",
    "    legal_cluster_id = arr[1].lower()\n",
    "    if corpus_legal_cluster_id.get(legal_cluster_id):\n",
    "        corpus_legal_cluster_id[legal_cluster_id].append(arr)\n",
    "    else:\n",
    "        corpus_legal_cluster_id[legal_cluster_id] = [arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tax_numbers(arr):\n",
    "    unique_tax_numbers = set()\n",
    "    for i in range(27, 33):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            unique_tax_numbers.add(arr[i].lower())\n",
    "    return unique_tax_numbers\n",
    "\n",
    "def extract_bvd_numbers(arr):\n",
    "    unique_bvd_numbers = set()\n",
    "    for i in range(24, 27):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            unique_bvd_numbers.add(arr[i].lower())\n",
    "    return unique_bvd_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def match_tax(arr):\n",
    "    tax = extract_tax_numbers(arr)\n",
    "    for tax_num in tax:\n",
    "        if tax_num in unique_tax_numbers:\n",
    "            return unique_tax_numbers[tax_num]\n",
    "    return None\n",
    "\n",
    "def match_bvd(arr):\n",
    "    bvd = extract_bvd_numbers(arr)\n",
    "    for bvd_num in bvd:\n",
    "        if bvd_num in unique_bvd_numbers:\n",
    "            return unique_bvd_numbers[bvd_num]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_top_matches(top_matches):\n",
    "    matches = {}\n",
    "    sorted_matches = sorted(top_matches, key=lambda x: x[0], reverse=True)\n",
    "    rank = 1\n",
    "    for idx, match in enumerate(sorted_matches):\n",
    "        score = match[0]\n",
    "        match_info = {\n",
    "            \"score\" : score,\n",
    "            \"customer_info\" : match[1]\n",
    "        }\n",
    "        matches[rank].append(match_info)\n",
    "        rank += 1\n",
    "        flag = False\n",
    "        legal_cluster_id = match[1][1]\n",
    "        # print(match)\n",
    "        # print(legal_cluster_id)\n",
    "        for r, existing_match in matches.items():\n",
    "            if existing_match[0][\"customer_info\"][1] == legal_cluster_id:\n",
    "                matches[r].append(match_info)\n",
    "                flag = True\n",
    "                break\n",
    "        if not flag:\n",
    "            matches[rank] = [match_info]\n",
    "            rank += 1\n",
    "    print(matches)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "success = 0\n",
    "failure = 0\n",
    "not_applicable = 0\n",
    "result = {}\n",
    "for arr in tqdm(data[num_customer_corpus:]):\n",
    "    customer_cmd_code = arr[2].lower()\n",
    "    # print(customer_cmd_code)\n",
    "    legal_cluster_id = arr[1].lower()\n",
    "    #checking if the test customer is in the corpus for the comparison\n",
    "    if legal_cluster_id in corpus_legal_cluster_id.keys():\n",
    "        matches = {}\n",
    "        #tax matching\n",
    "        tax_match = match_tax(arr)\n",
    "        if tax_match:\n",
    "            success += 1\n",
    "            matches[1] = tax_match\n",
    "            result[str(arr)] = matches\n",
    "            continue\n",
    "        #bvd matching\n",
    "        bvd_match = match_bvd(arr)\n",
    "        if bvd_match:\n",
    "            success += 1\n",
    "            matches[1] = bvd_match\n",
    "            result[str(arr)] = matches\n",
    "            continue\n",
    "\n",
    "        #trading name matching after country filtering \n",
    "        country_name = arr[16].lower()\n",
    "        #filtering by country and hence reducing our search space\n",
    "        if country_wise_corpus.get(country_name) is None:\n",
    "            not_applicable += 1\n",
    "            continue\n",
    "        filtered_corpus = country_wise_corpus[country_name]\n",
    "        print(country_name, len(filtered_corpus))\n",
    "        company_name = arr[4]\n",
    "        cleaned_company_name = clean_company_name(company_name)\n",
    "        best_match, best_score, top_matches = match_name(cleaned_company_name, filtered_corpus)\n",
    "        reformatted_top_matches = reformat_top_matches(top_matches)\n",
    "        if legal_cluster_id == best_match[1]:\n",
    "            success +=1\n",
    "        else:\n",
    "            failure +=1\n",
    "        if reformatted_top_matches.get(1):\n",
    "            # print(reformatted_top_matches[1][0]['customer_info'][1])\n",
    "            if legal_cluster_id == reformatted_top_matches[1][0]['customer_info'][1]:\n",
    "                success +=1\n",
    "            else:\n",
    "                failure +=1\n",
    "        \n",
    "        matches = reformat_top_matches(top_matches)\n",
    "        result[str(arr)] = matches\n",
    "        \n",
    "    else:\n",
    "        not_applicable +=1    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('result_match_tax_bvd_name_country-2-3-4.json', 'w') as f:\n",
    "    json.dump(result, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(success, failure, not_applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success/(failure + success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success + failure + not_applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
