{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from csv\n",
    "import csv\n",
    "input_file_path = \"/Users/k.abhishek/Documents/customer_clusters/export_all_v2.csv\"\n",
    "def load_data(input_file_path):\n",
    "    with open(input_file_path, mode ='r') as file:\n",
    "        csvFile = csv.reader(file)\n",
    "        data = list(csvFile)\n",
    "    return data\n",
    "\n",
    "data = load_data(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_in_focus = [\"IN\", \"CN\", \"US\"]\n",
    "# countries_in_focus = [\"IN\"]\n",
    "country_filter = set(countries_in_focus)\n",
    "\n",
    "#filtering based on country code\n",
    "filtered_data = [ d for d in data if d[15] in country_filter]\n",
    "import random \n",
    "random.seed(42)\n",
    "random.shuffle(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the unique values of legal_cluster_id\n",
    "\n",
    "legal_cluster_id = set([d[1] for d in filtered_data])\n",
    "# print(len(legal_cluster_id))\n",
    "\n",
    "legal_cluster_id_to_data = {}\n",
    "for d in filtered_data:\n",
    "    if legal_cluster_id_to_data.get(d[1]) is None:\n",
    "        legal_cluster_id_to_data[d[1]] = [d]\n",
    "    else:\n",
    "        legal_cluster_id_to_data[d[1]].append(d)    \n",
    "filtered_data = []\n",
    "num_entries = 100000\n",
    "test_corpus = []\n",
    "comparison_corpus = []\n",
    "count_entries = 0\n",
    "for legal_cluster_id, entry in legal_cluster_id_to_data.items():\n",
    "    if count_entries > num_entries:\n",
    "        break\n",
    "    if len(entry) > 1:\n",
    "        filtered_data.extend(entry)\n",
    "        count_entries += len(entry)\n",
    "        test_corpus.append(entry[0])\n",
    "        comparison_corpus.extend(entry[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tax_numbers(arr):\n",
    "    unique_tax_numbers = set()\n",
    "    for i in range(27, 33):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            unique_tax_numbers.add(arr[i].lower())\n",
    "    return unique_tax_numbers\n",
    "\n",
    "def extract_bvd_numbers(arr):\n",
    "    unique_bvd_numbers = set()\n",
    "    for i in range(24, 27):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            unique_bvd_numbers.add(arr[i].lower())\n",
    "    return unique_bvd_numbers\n",
    "\n",
    "def match_tax(arr, unique_tax_numbers):\n",
    "    tax = extract_tax_numbers(arr)\n",
    "    for tax_num in tax:\n",
    "        if tax_num in unique_tax_numbers:\n",
    "            return unique_tax_numbers[tax_num]\n",
    "    return None\n",
    "\n",
    "def match_bvd(arr, unique_bvd_numbers):\n",
    "    bvd = extract_bvd_numbers(arr)\n",
    "    for bvd_num in bvd:\n",
    "        if bvd_num in unique_bvd_numbers:\n",
    "            return unique_bvd_numbers[bvd_num]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tax_numbers = {}\n",
    "unique_bvd_numbers = {}\n",
    "for idx, arr in enumerate(comparison_corpus):\n",
    "    country_code = arr[15]\n",
    "    for i in range(24, 27):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            if unique_bvd_numbers.get(arr[i].lower()):\n",
    "                unique_bvd_numbers[arr[i].lower()].append(arr)\n",
    "            else:\n",
    "                unique_bvd_numbers[arr[i].lower()] = [arr]\n",
    "            # unique_bvd_numbers[arr[i]] = arr\n",
    "    for i in range(27, 33):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            if unique_tax_numbers.get(arr[i].lower()):\n",
    "                unique_tax_numbers[arr[i].lower()].append(arr)\n",
    "            else:\n",
    "                unique_tax_numbers[arr[i].lower()] = [arr]\n",
    "            # unique_tax_numbers[arr[i]] = arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from rapidfuzz import fuzz\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "import re\n",
    "stop_words = {'llp', 'ltd', 'llc', 'plc', 'inc', 'corp', 'nv', 'group', 'gmbh', 'sa', 'company', 'corporation', 'limited'}\n",
    "delimiters = {\".\", \",\", \"-\", \"_\", \"'\", \"&\", \"/\", \"\\\\\", \":\", \";\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \" \"}\n",
    "def split_company_name(name):\n",
    "    pattern = '|'.join(map(re.escape, delimiters))\n",
    "    words = re.split(pattern, name)\n",
    "    return [word for word in words if word]\n",
    "\n",
    "def lowercase_company_name(name):\n",
    "    return name.lower()\n",
    "\n",
    "# List of common delimiters\n",
    "def remove_stop_words(words):\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "def preprocess_name_2(trading_name):\n",
    "    # Lowercase the company name\n",
    "    trading_name = lowercase_company_name(trading_name)\n",
    "    # Split the company name into words\n",
    "    words = split_company_name(trading_name)\n",
    "    # Remove stop words\n",
    "    clean_name = remove_stop_words(words)\n",
    "    return clean_name\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_name_1(name):\n",
    "    name = name.lower()\n",
    "    name = re.sub(r'[^\\w\\s]', '', name)  # Remove punctuation\n",
    "    tokens = name.split()\n",
    "    tokens.sort()  # Sort tokens for token_sort_ratio\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "preprocess_name = preprocess_name_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the entire corpus\n",
    "# corpus_of_names = [\"John Doe\", \"Jane Smith\", \"Alice Johnson\"]  # Add all million names here\n",
    "corpus_of_names = [d[4] for d in comparison_corpus]\n",
    "preprocessed_names = [preprocess_name(name) for name in corpus_of_names]\n",
    "\n",
    "# Build Annoy index\n",
    "embedding_dim = 128  # Dimensionality of the embeddings\n",
    "annoy_index = AnnoyIndex(embedding_dim, 'angular')\n",
    "\n",
    "# Convert names to vectors (simple bag-of-words vectorization)\n",
    "def name_to_vector(name):\n",
    "    vector = np.zeros(embedding_dim)\n",
    "    tokens = name.split()\n",
    "    for token in tokens:\n",
    "        for char in token:\n",
    "            vector[ord(char) % embedding_dim] += 1  \n",
    "    return vector\n",
    "\n",
    "name_vectors = [name_to_vector(name) for name in preprocessed_names]\n",
    "\n",
    "for i, vector in enumerate(name_vectors):\n",
    "    # print(i, vector)\n",
    "    annoy_index.add_item(i, vector)\n",
    "\n",
    "annoy_index.build(50)  # 10 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuzzy matching score function\n",
    "function_selection = {\n",
    "    \"ratio\": 1,\n",
    "    \"partial_ratio\": 0,\n",
    "    \"token_sort_ratio\": 1,\n",
    "    \"token_set_ratio\": 1,\n",
    "    \"partial_token_sort_ratio\": 0,\n",
    "    \"partial_token_set_ratio\": 0\n",
    "}\n",
    "def combined_fuzzy_score(name1, name2):\n",
    "    ratio = fuzz.ratio(name1, name2) * function_selection[\"ratio\"]\n",
    "    partial_ratio = fuzz.partial_ratio(name1, name2) * function_selection[\"partial_ratio\"]\n",
    "    token_sort_ratio = fuzz.token_sort_ratio(name1, name2)  * function_selection[\"token_sort_ratio\"]\n",
    "    token_set_ratio = fuzz.token_set_ratio(name1, name2)    * function_selection[\"token_set_ratio\"]\n",
    "    partial_token_sort_ratio = fuzz.partial_token_sort_ratio(name1, name2) * function_selection[\"partial_token_sort_ratio\"]\n",
    "    partial_token_set_ratio = fuzz.partial_token_set_ratio(name1, name2) * function_selection[\"partial_token_set_ratio\"]\n",
    "    # print(f\"ratio: {ratio}, partial_ratio: {partial_ratio}, token_sort_ratio: {token_sort_ratio}, token_set_ratio: {token_set_ratio}, partial_token_sort_ratio: {partial_token_sort_ratio}, partial_token_set_ratio: {partial_token_set_ratio}\")\n",
    "    # print(f\"Ratios: {ratio}, {partial_ratio}, {token_sort_ratio}, {token_set_ratio}, {partial_token_sort_ratio}, {partial_token_set_ratio}\")\n",
    "    return sum([ratio, partial_ratio, token_sort_ratio, token_set_ratio, partial_token_sort_ratio, partial_token_set_ratio])/sum(function_selection.values())\n",
    "    # return max(ratio, partial_ratio, token_sort_ratio, token_set_ratio, partial_token_sort_ratio, partial_token_set_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find best match\n",
    "def find_best_match(input_name, num_candidates=15):\n",
    "    preprocessed_input = preprocess_name(input_name)\n",
    "    input_vector = name_to_vector(preprocessed_input)\n",
    "    \n",
    "    # Retrieve nearest neighbors using Annoy\n",
    "    nearest_neighbors = annoy_index.get_nns_by_vector(input_vector, num_candidates, include_distances=False)\n",
    "    # print(nearest_neighbors)\n",
    "    best_match_score = 0\n",
    "    best_match_name = None\n",
    "    best_match_idx = None\n",
    "    for neighbor_idx in nearest_neighbors:\n",
    "        candidate = preprocessed_names[neighbor_idx]\n",
    "        score = combined_fuzzy_score(preprocessed_input, candidate)\n",
    "        if score > best_match_score:\n",
    "            best_match_score = score\n",
    "            best_match_name = corpus_of_names[neighbor_idx]\n",
    "            best_match_idx = neighbor_idx\n",
    "    \n",
    "    return best_match_name, best_match_score, best_match_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12024/12024 [00:06<00:00, 1939.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "success = 0\n",
    "failure = 0\n",
    "not_applicable = 0\n",
    "result = {}\n",
    "result_flagged_existing = {}\n",
    "qualified_as_match_threshold = 0\n",
    "correctly_qualified_as_match_threshold = 0\n",
    "count_entries_name_matching =0\n",
    "threshold = 85\n",
    "for arr in tqdm(test_corpus):\n",
    "    legal_cluster_id = arr[1].lower()\n",
    "    country_code = arr[15]\n",
    "    matches = {}\n",
    "    #tax matching\n",
    "    tax_match = match_tax(arr, unique_tax_numbers)\n",
    "    if tax_match:\n",
    "        success += 1\n",
    "        matches[1] = tax_match\n",
    "        result[str(arr)] = matches\n",
    "        continue\n",
    "    #bvd matching\n",
    "    bvd_match = match_bvd(arr, unique_bvd_numbers)\n",
    "    if bvd_match:\n",
    "        success += 1\n",
    "        matches[1] = bvd_match\n",
    "        result[str(arr)] = matches\n",
    "        continue\n",
    "    # print(\"Name matching\")\n",
    "    company_name = arr[4]\n",
    "    count_entries_name_matching += 1\n",
    "    best_match_name, best_match_score, best_match_idx = find_best_match(company_name)\n",
    "    best_matched_entry = comparison_corpus[best_match_idx]\n",
    "    if best_match_score > threshold:\n",
    "        # print(best_match_score)\n",
    "        qualified_as_match_threshold +=1\n",
    "        result_flagged_existing[str(arr)] = best_matched_entry\n",
    "        if legal_cluster_id == best_matched_entry[1]:\n",
    "            success +=1\n",
    "            correctly_qualified_as_match_threshold +=1\n",
    "        else:\n",
    "            failure +=1\n",
    "    else:\n",
    "        failure +=1\n",
    "    result[str(arr)] = best_matched_entry\n",
    "    # print(idx+1, success, failure, success + failure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9853 2171\n",
      "8506 7775\n"
     ]
    }
   ],
   "source": [
    "print(success, failure)\n",
    "print(qualified_as_match_threshold, correctly_qualified_as_match_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9140606630613685\n"
     ]
    }
   ],
   "source": [
    "precision = correctly_qualified_as_match_threshold/qualified_as_match_threshold\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "save_result_filename = \"result_name_matching_threshold_85.json\"\n",
    "save_folder_path = \"/Users/k.abhishek/Documents/customer_clusters/experiments/approximate_match_approach/results\"\n",
    "save_result_file_path = os.path.join(save_folder_path, save_result_filename)\n",
    "\n",
    "def save_result(result, save_result_file_path):\n",
    "    import json\n",
    "    with open(save_result_file_path, 'w') as f:\n",
    "        json.dump(result, f)\n",
    "\n",
    "save_result(result, save_result_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
