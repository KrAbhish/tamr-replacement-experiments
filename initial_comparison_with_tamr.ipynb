{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index(['SITE_CLUSTER_ID', 'LEGAL_CLUSTER_ID', 'customer_cmd_code',\n",
    "       'customer_role_type', 'trading_name', 'street_no', 'address_line1',\n",
    "       'pobox', 'address_line2', 'address_line3', 'district', 'city',\n",
    "       'postal_code', 'state_code', 'state_name', 'country_code',\n",
    "       'country_name', 'phone_type', 'isd_country_code', 'isd_dialing_code',\n",
    "       'extension_number', 'phone_num', 'create_time', 'customer_cmd_code.1',\n",
    "       'BVD', 'BVD_HQ', 'BVD_GUO', 'TAXNO1', 'TAXNO2', 'TAXNO3', 'TAXNO4',\n",
    "       'TAXNO5', 'VATREG'],\n",
    "      dtype='object')\n",
    "{0: 'SITE_CLUSTER_ID', 1: 'LEGAL_CLUSTER_ID', 2: 'customer_cmd_code', 3: 'customer_role_type', 4: 'trading_name', 5: 'street_no', 6: 'address_line1', 7: 'pobox', 8: 'address_line2', 9: 'address_line3', 10: 'district', 11: 'city', 12: 'postal_code', 13: 'state_code', 14: 'state_name', 15: 'country_code', 16: 'country_name', 17: 'phone_type', 18: 'isd_country_code', 19: 'isd_dialing_code', 20: 'extension_number', 21: 'phone_num', 22: 'create_time', 23: 'customer_cmd_code.1', 24: 'BVD', 25: 'BVD_HQ', 26: 'BVD_GUO', 27: 'TAXNO1', 28: 'TAXNO2', 29: 'TAXNO3', 30: 'TAXNO4', 31: 'TAXNO5', 32: 'VATREG'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "delimiters = {\".\", \",\", \"-\", \"_\", \"'\", \"&\", \"/\", \"\\\\\", \":\", \";\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \" \"}\n",
    "def split_company_name(name):\n",
    "    pattern = '|'.join(map(re.escape, delimiters))\n",
    "    words = re.split(pattern, name)\n",
    "    return [word for word in words if word]\n",
    "\n",
    "def lowercase_company_name(name):\n",
    "    return name.lower()\n",
    "\n",
    "def clean_country_name(trading_name):\n",
    "    # Lowercase the company name\n",
    "    trading_name = lowercase_company_name(trading_name)\n",
    "    # Split the company name into words\n",
    "    words = split_company_name(trading_name)\n",
    "    # Remove stop words\n",
    "    clean_name = \" \".join(words)\n",
    "    return clean_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "customer_cmd_code_to_bvd = {}\n",
    "# with open('export.csv', mode ='r') as file:\n",
    "#     csvFile = csv.reader(file)\n",
    "#     data = list(csvFile)\n",
    "\n",
    "for idx, arr in enumerate(data[1:]):\n",
    "    tax = set()\n",
    "    for i in range(24, 27):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            # print(type(arr[i]))\n",
    "            tax.add(arr[i])\n",
    "            # print(tax)\n",
    "\n",
    "    if customer_cmd_code_to_bvd.get(arr[2]) is None:\n",
    "        customer_cmd_code_to_bvd[arr[2]] = tax\n",
    "    else:\n",
    "        customer_cmd_code_to_bvd[arr[2]] = customer_cmd_code_to_bvd[arr[2]].union(tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_bvd_num = 0\n",
    "bvd_num_exists = 0\n",
    "more_than_one_bvd_num = 0\n",
    "# count = 10\n",
    "for key, value in customer_cmd_code_to_bvd.items():\n",
    "    if len(value) == 0:\n",
    "        no_bvd_num += 1\n",
    "    else:\n",
    "        bvd_num_exists += 1\n",
    "    if len(value) > 1:\n",
    "        more_than_one_bvd_num += 1\n",
    "    # count -= 1\n",
    "    # if count == 0:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284915\n",
      "2940834\n",
      "669759\n"
     ]
    }
   ],
   "source": [
    "print(more_than_one_bvd_num)\n",
    "print(no_bvd_num)\n",
    "print(bvd_num_exists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for now generating 3 types of corpus for comparison:\n",
    "1. set of tax number\n",
    "2. set of bvd number\n",
    "3. dict of customer_cmd_code to list of entries corresponding to the same customer_cmd_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stop_words = {'llp', 'ltd', 'llc', 'plc', 'inc', 'corp', 'nv', 'group', 'gmbh', 'sa', 'company', 'corporation', 'limited'}\n",
    "delimiters = {\".\", \",\", \"-\", \"_\", \"'\", \"&\", \"/\", \"\\\\\", \":\", \";\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \" \"}\n",
    "def split_company_name(name):\n",
    "    pattern = '|'.join(map(re.escape, delimiters))\n",
    "    words = re.split(pattern, name)\n",
    "    return [word for word in words if word]\n",
    "\n",
    "def lowercase_company_name(name):\n",
    "    return name.lower()\n",
    "\n",
    "# List of common delimiters\n",
    "def remove_stop_words(words):\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "def clean_company_name(trading_name):\n",
    "    # Lowercase the company name\n",
    "    trading_name = lowercase_company_name(trading_name)\n",
    "    # Split the company name into words\n",
    "    words = split_company_name(trading_name)\n",
    "    # Remove stop words\n",
    "    clean_name = remove_stop_words(words)\n",
    "    return clean_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_number_matches = 5\n",
    "from time import time\n",
    "from rapidfuzz import fuzz, process\n",
    "import heapq\n",
    "def sorted_tokens(name):\n",
    "    return \" \".join(sorted(name.split()))\n",
    "\n",
    "#calculates the minimum number of edits (insertions, deletions, substitutions) needed to transform one string into another.\n",
    "#For typos or minor spelling variations\n",
    "def levenshtein_matching_score(input_name, name):\n",
    "    levenshtein_matching_score = fuzz.ratio(input_name, name)\n",
    "    return levenshtein_matching_score\n",
    "\n",
    "#split strings into tokens (words) and compare the intersection and order of these tokens. This is useful for handling different word orders or missing words in one string.\n",
    "def token_set_matching_score(input_name, name):\n",
    "    token_set_matching_score = fuzz.token_set_ratio(input_name, name)\n",
    "    return token_set_matching_score\n",
    "\n",
    "#For situations with extra content or partial matches:\n",
    "def partial_matching_score(input_name, name):\n",
    "    partial_matching_score = fuzz.partial_token_set_ratio(input_name, name)\n",
    "    return partial_matching_score\n",
    "\n",
    "#focus on finding matching subsequences within strings. This is beneficial when comparing strings with extra content or typos.\n",
    "#For typos or minor spelling variations\n",
    "def substring_matching_score(input_name, name):\n",
    "    substring_matching_score = fuzz.partial_ratio(input_name, name)\n",
    "    return substring_matching_score\n",
    "\n",
    "#split strings into tokens (words) and compare the intersection and order of these tokens. This is useful for handling different word orders or missing words in one string.\n",
    "def token_sort_ratio_score(input_name, name):\n",
    "    score = fuzz.token_sort_ratio(input_name, name)\n",
    "    return score\n",
    "# Matching\n",
    "\n",
    "def match_name_top_matches(input_name, corpus):\n",
    "    input_name = clean_company_name(input_name)\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    top_matches = []\n",
    "    heapq.heapify(top_matches)\n",
    "    similarity_measures = { \n",
    "        \"levenshtein_matching_score\" : (1, levenshtein_matching_score),\n",
    "        \"token_set_matching_score\" : (1, token_set_matching_score),\n",
    "        \"substring_matching_score\" : (0, substring_matching_score),\n",
    "        \"partial_matching_score\" : (0, partial_matching_score),\n",
    "        \"token_sort_ratio_score\" : (1, token_sort_ratio_score)\n",
    "    }\n",
    "    print(\"Length of corpus: \", len(corpus))\n",
    "    s_time = time()\n",
    "    for customer_info in corpus:\n",
    "        name = customer_info[4]\n",
    "        name = clean_company_name(name)\n",
    "        num_measures = 0\n",
    "        total_score = 0\n",
    "        for func_key, function_check in similarity_measures.items():\n",
    "            check, func = function_check\n",
    "            s_func_time = time()\n",
    "            \n",
    "            if check:\n",
    "                score = func(input_name, name)\n",
    "                total_score += score\n",
    "                num_measures +=1\n",
    "            if num_measures == 0:\n",
    "                combined_score = 0\n",
    "            else:\n",
    "                combined_score = total_score / num_measures\n",
    "        if len(top_matches) < max_number_matches:\n",
    "            heapq.heappush(top_matches, (combined_score, customer_info))\n",
    "        else:\n",
    "            heapq.heappushpop(top_matches, (combined_score, customer_info))\n",
    "        if combined_score > best_score:\n",
    "            best_score = combined_score\n",
    "            best_match = customer_info\n",
    "    e_time = time()\n",
    "    print(\"Time taken: \", e_time - s_time)\n",
    "    return best_match, best_score, top_matches\n",
    "\n",
    "def match_name(input_name, corpus):\n",
    "    input_name = clean_company_name(input_name)\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    top_matches = []\n",
    "    heapq.heapify(top_matches)\n",
    "    similarity_measures = { \n",
    "        \"levenshtein_matching_score\" : (1, levenshtein_matching_score),\n",
    "        \"token_set_matching_score\" : (1, token_set_matching_score),\n",
    "        \"substring_matching_score\" : (1, substring_matching_score),\n",
    "        \"partial_matching_score\" : (1, partial_matching_score),\n",
    "        \"token_sort_ratio_score\" : (1, token_sort_ratio_score)\n",
    "    }\n",
    "    for customer_info in corpus:\n",
    "        name = customer_info[4]\n",
    "        name = clean_company_name(name)\n",
    "        num_measures = 0\n",
    "        total_score = 0\n",
    "        for function_check in similarity_measures.values():\n",
    "            check, func = function_check\n",
    "            if check:\n",
    "                score = func(input_name, name)\n",
    "                total_score += score\n",
    "                num_measures +=1\n",
    "            if num_measures == 0:\n",
    "                combined_score = 0\n",
    "            else:\n",
    "                combined_score = total_score / num_measures\n",
    "        if len(top_matches) < max_number_matches:\n",
    "            heapq.heappush(top_matches, (combined_score, customer_info))\n",
    "        else:\n",
    "            heapq.heappushpop(top_matches, (combined_score, customer_info))\n",
    "        if combined_score > best_score:\n",
    "            best_score = combined_score\n",
    "            best_match = customer_info\n",
    "    \n",
    "    return best_match, best_score, top_matches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tax_numbers(arr):\n",
    "    unique_tax_numbers = set()\n",
    "    for i in range(27, 33):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            unique_tax_numbers.add(arr[i].lower())\n",
    "    return unique_tax_numbers\n",
    "\n",
    "def extract_bvd_numbers(arr):\n",
    "    unique_bvd_numbers = set()\n",
    "    for i in range(24, 27):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            unique_bvd_numbers.add(arr[i].lower())\n",
    "    return unique_bvd_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def match_tax(arr, unique_tax_numbers):\n",
    "    tax = extract_tax_numbers(arr)\n",
    "    for tax_num in tax:\n",
    "        if tax_num in unique_tax_numbers:\n",
    "            return unique_tax_numbers[tax_num]\n",
    "    return None\n",
    "\n",
    "def match_bvd(arr, unique_bvd_numbers):\n",
    "    bvd = extract_bvd_numbers(arr)\n",
    "    for bvd_num in bvd:\n",
    "        if bvd_num in unique_bvd_numbers:\n",
    "            return unique_bvd_numbers[bvd_num]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_top_matches(top_matches):\n",
    "    # print(top_matches)\n",
    "    matches = {}\n",
    "    sorted_matches = sorted(top_matches, key=lambda x: x[0], reverse=True)\n",
    "    rank = 1\n",
    "    for idx, match in enumerate(sorted_matches):\n",
    "        score = match[0]\n",
    "        match_info = {\n",
    "            \"score\" : score,\n",
    "            \"customer_info\" : match[1]\n",
    "        }\n",
    "        matches[rank] = [match_info]\n",
    "        rank += 1\n",
    "    # print(matches)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from csv\n",
    "import csv\n",
    "\n",
    "with open('export_all_v2.csv', mode ='r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    data = list(csvFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_in_focus = [\"IN\", \"CN\", \"US\"]\n",
    "# countries_in_focus = [\"IN\"]\n",
    "country_filter = set(countries_in_focus)\n",
    "\n",
    "#filtering based on country code\n",
    "filtered_data = [ d for d in data if d[15] in country_filter]\n",
    "import random \n",
    "random.seed(42)\n",
    "random.shuffle(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the unique values of legal_cluster_id\n",
    "\n",
    "legal_cluster_id = set([d[1] for d in filtered_data])\n",
    "# print(len(legal_cluster_id))\n",
    "\n",
    "legal_cluster_id_to_data = {}\n",
    "for d in filtered_data:\n",
    "    if legal_cluster_id_to_data.get(d[1]) is None:\n",
    "        legal_cluster_id_to_data[d[1]] = [d]\n",
    "    else:\n",
    "        legal_cluster_id_to_data[d[1]].append(d)    \n",
    "filtered_data = []\n",
    "num_entries = 100000\n",
    "test_corpus = []\n",
    "comparison_corpus = []\n",
    "count_entries = 0\n",
    "for legal_cluster_id, entry in legal_cluster_id_to_data.items():\n",
    "    if count_entries > num_entries:\n",
    "        break\n",
    "    if len(entry) > 1:\n",
    "        filtered_data.extend(entry)\n",
    "        count_entries += len(entry)\n",
    "        test_corpus.append(entry[0])\n",
    "        comparison_corpus.extend(entry[1:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_wise_corpus = {}\n",
    "for entries in comparison_corpus:\n",
    "    country_code = entries[15]\n",
    "    if country_wise_corpus.get(country_code) is None:\n",
    "        country_wise_corpus[country_code] = [entries]\n",
    "    else:\n",
    "        country_wise_corpus[country_code].append(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29830"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(country_wise_corpus[\"US\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12024 87978\n"
     ]
    }
   ],
   "source": [
    "print(len(test_corpus), len(comparison_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tax_numbers = {}\n",
    "unique_bvd_numbers = {}\n",
    "for idx, arr in enumerate(comparison_corpus):\n",
    "    country_code = arr[15]\n",
    "    for i in range(24, 27):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            if unique_bvd_numbers.get(arr[i].lower()):\n",
    "                unique_bvd_numbers[arr[i].lower()].append(arr)\n",
    "            else:\n",
    "                unique_bvd_numbers[arr[i].lower()] = [arr]\n",
    "            # unique_bvd_numbers[arr[i]] = arr\n",
    "    for i in range(27, 33):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            if unique_tax_numbers.get(arr[i].lower()):\n",
    "                unique_tax_numbers[arr[i].lower()].append(arr)\n",
    "            else:\n",
    "                unique_tax_numbers[arr[i].lower()] = [arr]\n",
    "            # unique_tax_numbers[arr[i]] = arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 8796/12024 [1:44:47<53:04,  1.01it/s]  "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "success = 0\n",
    "failure = 0\n",
    "not_applicable = 0\n",
    "result = {}\n",
    "result_flagged_existing = {}\n",
    "qualified_as_match_threshold = 0\n",
    "correctly_qualified_as_match_threshold = 0\n",
    "count_entries_name_matching =0\n",
    "threshold = 95\n",
    "for arr in tqdm(test_corpus):\n",
    "    legal_cluster_id = arr[1].lower()\n",
    "    country_code = arr[15]\n",
    "    matches = {}\n",
    "    #tax matching\n",
    "    tax_match = match_tax(arr, unique_tax_numbers)\n",
    "    if tax_match:\n",
    "        success += 1\n",
    "        matches[1] = tax_match\n",
    "        result[str(arr)] = matches\n",
    "        continue\n",
    "    #bvd matching\n",
    "    bvd_match = match_bvd(arr, unique_bvd_numbers)\n",
    "    if bvd_match:\n",
    "        success += 1\n",
    "        matches[1] = bvd_match\n",
    "        result[str(arr)] = matches\n",
    "        continue\n",
    "    # print(\"Name matching\")\n",
    "    company_name = arr[4]\n",
    "    cleaned_company_name = clean_company_name(company_name)\n",
    "    comparison_corpus = country_wise_corpus[country_code]\n",
    "    best_match, best_score, top_matches = match_name(cleaned_company_name, comparison_corpus)\n",
    "    # print(len(top_matches))\n",
    "    reformatted_top_matches = reformat_top_matches(top_matches)\n",
    "    count_entries_name_matching += 1\n",
    "    if reformatted_top_matches[1][0]['score'] > threshold:\n",
    "        qualified_as_match_threshold +=1\n",
    "        result_flagged_existing[str(arr)] = reformatted_top_matches\n",
    "        if legal_cluster_id == reformatted_top_matches[1][0]['customer_info'][1]:\n",
    "            success +=1\n",
    "            correctly_qualified_as_match_threshold +=1\n",
    "        else:\n",
    "            failure +=1\n",
    "    else:\n",
    "        failure +=1\n",
    "    matches = reformatted_top_matches\n",
    "    result[str(arr)] = matches\n",
    "    # print(idx+1, success, failure, success + failure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9414 2610 0\n",
      "7498 7336\n"
     ]
    }
   ],
   "source": [
    "print(success, failure, not_applicable)\n",
    "print(qualified_as_match_threshold, correctly_qualified_as_match_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9946"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_entries_name_matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(success, failure, not_applicable)\n",
    "print(qualified_as_match_threshold, correctly_qualified_as_match_threshold)\n",
    "11714 2105 0\n",
    "5554 5326"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9414 2610\n"
     ]
    }
   ],
   "source": [
    "print(success, failure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7829341317365269"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success/(success+failure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7498"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualified_as_match_threshold - correctly_qualified_as_match_threshold\n",
    "qualified_as_match_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9783942384635903"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correctly_qualified_as_match_threshold/qualified_as_match_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('ind_cn_us_ss_result_match_tax_bvd_name_country-1-2-3-4-5.json', 'w') as f:\n",
    "    json.dump(result, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5554"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_flagged_existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_name = \"ind_cn_us\" + \"_threshold_\" + str(threshold) + \"_qualified_\" + str(qualified_as_match_threshold) + \"_correctly_qualified_\" + str(correctly_qualified_as_match_threshold) + \".json\"\n",
    "import json\n",
    "with open(save_file_name, 'w') as f:\n",
    "    json.dump(result_flagged_existing, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0387724e-a2be-3546-b8b5-5be05692a314',\n",
       "  'd3e3b0f7-2913-3acb-813a-2ebfd91667c6',\n",
       "  'IN02814037',\n",
       "  'Customer',\n",
       "  'KUMASS INTERNATIONAL',\n",
       "  'null',\n",
       "  'COURT COMPOUND',\n",
       "  'null',\n",
       "  '52-SHRI RAMVIHAR COLONY',\n",
       "  'null',\n",
       "  'null',\n",
       "  'MORADABAD',\n",
       "  '244001',\n",
       "  'UP',\n",
       "  'UTTAR PRADESH',\n",
       "  'IN',\n",
       "  'INDIA',\n",
       "  'TEL',\n",
       "  'IN',\n",
       "  '91',\n",
       "  'null',\n",
       "  '5912483311',\n",
       "  '2021-06-29T13:07:51.696Z',\n",
       "  'IN02814037',\n",
       "  'IN0022345582',\n",
       "  'null',\n",
       "  'null',\n",
       "  'AAJFK8002H',\n",
       "  '09AAJFK8002H1ZB',\n",
       "  'null',\n",
       "  'null',\n",
       "  'null',\n",
       "  'null'],\n",
       " ['6cca5155-b0f8-3421-8c4d-21df15a070cc',\n",
       "  '0f228f32-a9c6-3cec-b9dd-0aede7d2e684',\n",
       "  'IN02924619',\n",
       "  'Customer',\n",
       "  'SAMVARDHANA MOTHERSON INTERNATIONAL LIMITED',\n",
       "  '1ST PHASE',\n",
       "  'PHASE-1 MOTHERSON SUMI SYSTEMS LTD',\n",
       "  'null',\n",
       "  'PLOT NO 14 KIADB INDUSTRIAL AREA',\n",
       "  'MYSORE ROAD KUMBALGODU',\n",
       "  'null',\n",
       "  'BENGALURU',\n",
       "  '560074',\n",
       "  'KA',\n",
       "  'KARNATAKA',\n",
       "  'IN',\n",
       "  'India',\n",
       "  'MOB',\n",
       "  'IN',\n",
       "  '91',\n",
       "  'null',\n",
       "  '8023010824',\n",
       "  '2022-06-21T10:48:06.341Z',\n",
       "  'IN02924619',\n",
       "  'null',\n",
       "  'null',\n",
       "  'null',\n",
       "  'AAACM0405A',\n",
       "  '29AAACM0405A1Z9',\n",
       "  'AAACM0405A',\n",
       "  'null',\n",
       "  'null',\n",
       "  'null'],\n",
       " ['60962d0a-26b5-3750-ae54-607164d786c2',\n",
       "  '8d24058d-d069-3964-ba9a-e2ef09e21d96',\n",
       "  'IN02284964',\n",
       "  'Customer',\n",
       "  'GLOBAL IMPEX',\n",
       "  'null',\n",
       "  'BANNERGHATTA ROAD',\n",
       "  'null',\n",
       "  'SYNO - 119/5, SAKALVARA POST',\n",
       "  'null',\n",
       "  'null',\n",
       "  'BENGALURU',\n",
       "  '560030',\n",
       "  'KA',\n",
       "  'KARNATAKA',\n",
       "  'IN',\n",
       "  'India',\n",
       "  'TEL',\n",
       "  'IN',\n",
       "  '91',\n",
       "  'null',\n",
       "  '9902343611',\n",
       "  '2018-03-24T03:21:24.021Z',\n",
       "  'IN02284964',\n",
       "  'null',\n",
       "  'null',\n",
       "  'null',\n",
       "  'BFHPK2458F',\n",
       "  '29BFHPK2458F1ZB',\n",
       "  'BFHPK2458F',\n",
       "  'null',\n",
       "  'null',\n",
       "  'null'],\n",
       " ['860e0574-dde4-3827-8534-07749ad79ec6',\n",
       "  '739f5ecf-d530-3b2f-ac52-0ce6106a48db',\n",
       "  'IN02343672',\n",
       "  'Customer',\n",
       "  'KRISHNA RECYCLING INDUSTRIES',\n",
       "  'null',\n",
       "  'KUBADTHAL GAM ROAD',\n",
       "  'null',\n",
       "  'SURVEY BLOCK NO 957/ 958 KUBADTAL',\n",
       "  'INDORE-AHMEDABAD HIIGHWAY',\n",
       "  'null',\n",
       "  'AHMEDABAD',\n",
       "  '382433',\n",
       "  'GJ',\n",
       "  'GUJARAT',\n",
       "  'IN',\n",
       "  'INDIA',\n",
       "  'TEL',\n",
       "  'IN',\n",
       "  '91',\n",
       "  'null',\n",
       "  '9825207287',\n",
       "  '2019-05-02T12:15:27.911Z',\n",
       "  'IN02343672',\n",
       "  'null',\n",
       "  'null',\n",
       "  'null',\n",
       "  'AAUFK0234C',\n",
       "  '24AAUFK0234C1ZO',\n",
       "  'null',\n",
       "  'null',\n",
       "  'null',\n",
       "  'null'],\n",
       " ['4231d677-a6f4-354e-b098-4b44523ef1da',\n",
       "  'fed4fe04-13c1-3ee7-a189-1c49f5fe4141',\n",
       "  'IN01192318',\n",
       "  'Customer',\n",
       "  'JASH PHARMA CHEM',\n",
       "  'null',\n",
       "  '111, 1ST FLOOR, V KARSANDAS',\n",
       "  'null',\n",
       "  'NATHA TRUST BLDG,328/332,SAMUSTREET',\n",
       "  'null',\n",
       "  'null',\n",
       "  'MUMBAI',\n",
       "  '400003',\n",
       "  'MH',\n",
       "  'MAHARASHTRA',\n",
       "  'IN',\n",
       "  'India',\n",
       "  'TEL',\n",
       "  'IN',\n",
       "  '91',\n",
       "  'null',\n",
       "  '9821223359',\n",
       "  '2016-07-10T19:38:37.039Z',\n",
       "  'null',\n",
       "  'null',\n",
       "  'null',\n",
       "  'null',\n",
       "  'null',\n",
       "  'null',\n",
       "  'null',\n",
       "  'null',\n",
       "  'null',\n",
       "  'null']]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "random.seed(42)\n",
    "random.shuffle(filtered_data)\n",
    "filtered_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 95\n",
    "corpus_ratio = 0.9\n",
    "\n",
    "num_customer_corpus = int(len(filtered_data) * corpus_ratio)\n",
    "unique_tax_numbers = {}\n",
    "unique_bvd_numbers = {}\n",
    "country_wise_corpus = {}\n",
    "corpus_legal_cluster_id = {}\n",
    "for idx, arr in enumerate(filtered_data[:num_customer_corpus]):\n",
    "    country_code = arr[15]\n",
    "    for i in range(24, 27):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            if unique_bvd_numbers.get(arr[i].lower()):\n",
    "                unique_bvd_numbers[arr[i].lower()].append(arr)\n",
    "            else:\n",
    "                unique_bvd_numbers[arr[i].lower()] = [arr]\n",
    "            # unique_bvd_numbers[arr[i]] = arr\n",
    "    for i in range(27, 33):\n",
    "        if arr[i] and arr[i] != \"null\":\n",
    "            if unique_tax_numbers.get(arr[i].lower()):\n",
    "                unique_tax_numbers[arr[i].lower()].append(arr)\n",
    "            else:\n",
    "                unique_tax_numbers[arr[i].lower()] = [arr]\n",
    "            # unique_tax_numbers[arr[i]] = arr\n",
    "\n",
    "    if country_wise_corpus.get(country_code):\n",
    "        country_wise_corpus[country_code].append(arr)\n",
    "    else:\n",
    "        country_wise_corpus[country_code] = [arr]\n",
    "\n",
    "    legal_cluster_id = arr[1].lower()\n",
    "    if corpus_legal_cluster_id.get(legal_cluster_id):\n",
    "        corpus_legal_cluster_id[legal_cluster_id].append(arr)\n",
    "    else:\n",
    "        corpus_legal_cluster_id[legal_cluster_id] = [arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8704 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/8704 [00:01<3:57:02,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/8704 [00:03<2:23:20,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/8704 [00:03<1:41:54,  1.42it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m company_name \u001b[38;5;241m=\u001b[39m arr[\u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m     46\u001b[0m cleaned_company_name \u001b[38;5;241m=\u001b[39m clean_company_name(company_name)\n\u001b[0;32m---> 47\u001b[0m best_match, best_score, top_matches \u001b[38;5;241m=\u001b[39m \u001b[43mmatch_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleaned_company_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiltered_corpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m reformatted_top_matches \u001b[38;5;241m=\u001b[39m reformat_top_matches(top_matches)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m legal_cluster_id \u001b[38;5;241m==\u001b[39m best_match[\u001b[38;5;241m1\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[25], line 100\u001b[0m, in \u001b[0;36mmatch_name\u001b[0;34m(input_name, corpus)\u001b[0m\n\u001b[1;32m     98\u001b[0m check, func \u001b[38;5;241m=\u001b[39m function_check\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check:\n\u001b[0;32m--> 100\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     total_score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m score\n\u001b[1;32m    102\u001b[0m     num_measures \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[25], line 21\u001b[0m, in \u001b[0;36mpartial_matching_score\u001b[0;34m(input_name, name)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpartial_matching_score\u001b[39m(input_name, name):\n\u001b[0;32m---> 21\u001b[0m     partial_matching_score \u001b[38;5;241m=\u001b[39m \u001b[43mfuzz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_token_set_ratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m partial_matching_score\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "threshold = 90\n",
    "predicted_true = 0\n",
    "actual_true = 0\n",
    "predicted_false = 0\n",
    "from tqdm import tqdm\n",
    "success = 0\n",
    "failure = 0\n",
    "not_applicable = 0\n",
    "result = {}\n",
    "result_flagged_existing = {}\n",
    "for arr in tqdm(filtered_data[num_customer_corpus:]):\n",
    "    legal_cluster_id = arr[1].lower()\n",
    "    #checking if the test customer is in the corpus for the comparison\n",
    "    country_code = arr[15]\n",
    "    matches = {}\n",
    "    #tax matching\n",
    "    if legal_cluster_id in corpus_legal_cluster_id.keys():\n",
    "        tax_match = match_tax(arr)\n",
    "        if tax_match:\n",
    "            success += 1\n",
    "            matches[1] = tax_match\n",
    "            result[str(arr)] = matches\n",
    "            predicted_true +=1\n",
    "            actual_true +=1\n",
    "            continue\n",
    "        #bvd matching\n",
    "        bvd_match = match_bvd(arr)\n",
    "        if bvd_match:\n",
    "            success += 1\n",
    "            predicted_true +=1\n",
    "            actual_true +=1\n",
    "            matches[1] = bvd_match\n",
    "            result[str(arr)] = matches\n",
    "            continue\n",
    "\n",
    "        #trading name matching after country filtering \n",
    "        country_code = arr[15]\n",
    "        #filtering by country and hence reducing our search space\n",
    "        if country_wise_corpus.get(country_code) is None:\n",
    "            not_applicable += 1\n",
    "            print(\"Country code not found\")\n",
    "            continue\n",
    "        filtered_corpus = country_wise_corpus[country_code]\n",
    "        print(len(filtered_corpus))\n",
    "        company_name = arr[4]\n",
    "        cleaned_company_name = clean_company_name(company_name)\n",
    "        best_match, best_score, top_matches = match_name(cleaned_company_name, filtered_corpus)\n",
    "        reformatted_top_matches = reformat_top_matches(top_matches)\n",
    "        if legal_cluster_id == best_match[1]:\n",
    "            success +=1\n",
    "        else:\n",
    "            failure +=1\n",
    "        if reformatted_top_matches.get(1):\n",
    "            # print(reformatted_top_matches[1][0]['customer_info'][1])\n",
    "            if reformatted_top_matches[1][0]['score'] > threshold:\n",
    "                result_flagged_existing[str(arr)] = reformatted_top_matches\n",
    "                if legal_cluster_id == reformatted_top_matches[1][0]['customer_info'][1]:\n",
    "                    success +=1\n",
    "                    predicted_true +=1\n",
    "                    actual_true +=1\n",
    "            else:\n",
    "                failure +=1\n",
    "        \n",
    "        matches = reformat_top_matches(top_matches)\n",
    "        result[str(arr)] = matches\n",
    "    else:\n",
    "        not_applicable += 1\n",
    "    \n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('result_match_tax_bvd_name_country-2-3-4.json', 'w') as f:\n",
    "    json.dump(result, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3555 2627 9635\n"
     ]
    }
   ],
   "source": [
    "print(success, failure, not_applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_flagged_existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success/(failure + success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success + failure + not_applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
